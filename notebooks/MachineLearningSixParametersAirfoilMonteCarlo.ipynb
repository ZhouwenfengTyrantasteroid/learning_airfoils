{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airfoil experiments\n",
    "All data is available in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../python')\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from machine_learning import *\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_points_preprocessed = np.loadtxt('../mc6.txt')\n",
    "forces = np.loadtxt('../force_6_params_mc.dat')\n",
    "mc_points = []\n",
    "for f in forces[:,0]:\n",
    "    for n in range(mc_points_preprocessed.shape[0]):\n",
    "        if mc_points_preprocessed[n,0] == f:\n",
    "            mc_points.append(mc_points_preprocessed[n,:])\n",
    "mc_points = np.array(mc_points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_size=6\n",
    "train_size=128\n",
    "validation_size=128\n",
    "\n",
    "epochs = 500000\n",
    "\n",
    "\n",
    "airfoils_network = [12, 12, 10, 12, 10, 12, 10, 10, 12,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "batch_sizes=[train_size]\n",
    "train_sizes = [16, 32, train_size]\n",
    "\n",
    "optimizers = {\"SGD\": keras.optimizers.SGD,\n",
    "             \"Adam\": keras.optimizers.Adam}\n",
    "\n",
    "losses = [\"mean_squared_error\", \"mean_absolute_error\"]\n",
    "\n",
    "for optimizer in optimizers.keys():\n",
    "    for loss in losses:\n",
    "        display(HTML(\"<h1>{} with {}</h1>\".format(optimizer, loss)))\n",
    "\n",
    "        for batch_size in batch_sizes:\n",
    "            tables = Tables.make_default()\n",
    "            \n",
    "            for (n, f) in enumerate(force_names):\n",
    "                seed_random_number(random_seed)\n",
    "                network_information = NetworkInformation(optimizer=optimizers[optimizer], epochs=epochs, \n",
    "                                                         network=airfoils_network, train_size=train_size,\n",
    "                                                         validation_size=validation_size,\n",
    "                                                        loss=loss, \n",
    "                                                        large_integration_points=large_mc_points)\n",
    "                \n",
    "                output_information = OutputInformation(tables=tables, title=force_names[n],\n",
    "                                                      short_title=force_names[n],\n",
    "                                                      sampling_method='MC')\n",
    "                showAndSave.prefix='airfoil_mc_%s_%s_%s_ts_%d_bs_%d' %(optimizer, loss, f,batch_size, train_size)\n",
    "                get_network_and_postprocess(mc_points, forces[:,n+1], network_information = network_information,\n",
    "                    output_information = output_information)\n",
    "            \n",
    "            showAndSave.prefix='airfoil_mc_%s_%s_all_ts_%d_bs_%d' %(optimizer, loss, batch_size, train_size)\n",
    "            tables.write_tables()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As a function of training errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "epochs = 500000\n",
    "\n",
    "optimizers = {\"SGD\": keras.optimizers.SGD,\n",
    "             \"Adam\": keras.optimizers.Adam}\n",
    "loss = \"mean_squared_error\"\n",
    "optimizer='SGD'\n",
    "for n in range(len(force_names)):\n",
    "    f=force_names[n]\n",
    "    tables = Tables.make_default()\n",
    "    def run_function(network_information, output_information):\n",
    "        showAndSave.prefix='airfoil_mc_convergence_%s_%s_%s_ts_%d_bs_%d' %(optimizer, loss, f, \n",
    "                                                                        network_information.batch_size,\n",
    "                                                                        network_information.train_size)\n",
    "        showAndSave.silent=True\n",
    "        print_comparison_table.silent = True\n",
    "        get_network_and_postprocess(mc_points, forces[:,n+1], network_information = network_information,\n",
    "            output_information = output_information)\n",
    "        \n",
    "        showAndSave.prefix='airfoil_mc_convergence_result_%s_%s_%s' %(optimizer, loss, f)\n",
    "        \n",
    "        \n",
    "    network_information = NetworkInformation(optimizer=optimizers[optimizer], epochs=epochs, \n",
    "                                                     network=airfoils_network, train_size=None,\n",
    "                                                     validation_size=None,\n",
    "                                                    loss=loss, \n",
    "                                                    large_integration_points=None,\n",
    "                                                    tries=5)\n",
    "            \n",
    "    output_information = OutputInformation(tables=tables, title=force_names[n],\n",
    "                                          short_title=force_names[n], sampling_method='MC')\n",
    "    \n",
    "    plot_train_size_convergence(network_information,\n",
    "                               output_information, \n",
    "                               run_function,\n",
    "                               mc_points.shape[0]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_information.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
