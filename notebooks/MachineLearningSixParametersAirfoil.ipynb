{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airfoil experiments\n",
    "All data is available in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../python')\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from machine_learning import *\n",
    "from notebook_network_size import find_best_network_size_notebook\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmc_points = np.loadtxt('../sobol_6_8000.txt')\n",
    "qmc_points = qmc_points[1:].reshape((8000,6))\n",
    "\n",
    "large_qmc_points = np.loadtxt('../sobol_6_131072.txt')\n",
    "all_points = qmc_points.copy()\n",
    "forces = np.array(np.loadtxt('../force_6_params.dat'))\n",
    "\n",
    "\n",
    "N = min(qmc_points.shape[0], forces.shape[0])\n",
    "qmc_points = qmc_points[:N,:]\n",
    "forces  = forces[:N,:]\n",
    "\n",
    "\n",
    "input_size=6\n",
    "train_size=128\n",
    "validation_size=128\n",
    "\n",
    "epochs = 500000\n",
    "\n",
    "\n",
    "airfoils_network = [12, 12, 10, 12, 10, 12, 10, 10, 12,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network sizes\n",
    "\n",
    "Find the optimal network size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Best performing</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>mean_train</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Lift</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 4 x 6 ([0 x 0] / [4 x 4])\n",
      "Training and postprocessing took: 4169.638660669327 seconds (69.49397767782212 minutes) (1.1582329612970352 hours)\n",
      "Config 4 x 12 ([0 x 1] / [4 x 4])\n",
      "Training and postprocessing took: 4222.8033492565155 seconds (70.38005582094192 minutes) (1.173000930349032 hours)\n",
      "Config 4 x 24 ([0 x 2] / [4 x 4])\n",
      "Training and postprocessing took: 4369.747181653976 seconds (72.82911969423294 minutes) (1.213818661570549 hours)\n",
      "Config 4 x 48 ([0 x 3] / [4 x 4])\n",
      "Training and postprocessing took: 4553.94184756279 seconds (75.89903079271316 minutes) (1.2649838465452194 hours)\n",
      "Config 8 x 6 ([1 x 0] / [4 x 4])\n",
      "Training and postprocessing took: 5748.470389842987 seconds (95.80783983071645 minutes) (1.5967973305119407 hours)\n",
      "Config 8 x 12 ([1 x 1] / [4 x 4])\n",
      "Training and postprocessing took: 6142.488917589188 seconds (102.37481529315313 minutes) (1.7062469215525522 hours)\n",
      "Config 8 x 24 ([1 x 2] / [4 x 4])\n",
      "Training and postprocessing took: 6333.061476230621 seconds (105.55102460384369 minutes) (1.7591837433973947 hours)\n",
      "Config 8 x 48 ([1 x 3] / [4 x 4])\n",
      "Training and postprocessing took: 6794.067271947861 seconds (113.23445453246434 minutes) (1.8872409088744058 hours)\n",
      "Config 16 x 6 ([2 x 0] / [4 x 4])\n",
      "Training and postprocessing took: 8951.760599851608 seconds (149.1960099975268 minutes) (2.4866001666254465 hours)\n",
      "Config 16 x 12 ([2 x 1] / [4 x 4])\n",
      "Training and postprocessing took: 9576.72437119484 seconds (159.61207285324733 minutes) (2.660201214220789 hours)\n",
      "Config 16 x 24 ([2 x 2] / [4 x 4])\n",
      "Training and postprocessing took: 9969.914719104767 seconds (166.1652453184128 minutes) (2.76942075530688 hours)\n",
      "Config 16 x 48 ([2 x 3] / [4 x 4])\n",
      "Training and postprocessing took: 10526.19477057457 seconds (175.43657950957615 minutes) (2.923942991826269 hours)\n",
      "Config 32 x 6 ([3 x 0] / [4 x 4])\n"
     ]
    }
   ],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "\n",
    "optimizers = {\"SGD\": keras.optimizers.SGD,\n",
    "             \"Adam\": keras.optimizers.Adam}\n",
    "\n",
    "loss = \"mean_squared_error\"\n",
    "\n",
    "selections = {}\n",
    "selections['Best performing'] = ['mean_train', 'ray_prediction', 'wasserstein_train', 'train']\n",
    "selections['Emperically optimal'] = ['mean', 'mean_tail', 'prediction', 'wasserstein']\n",
    "\n",
    "\n",
    "\n",
    "class TrainingFunction(object):\n",
    "    def __init__(self, *, parameters, samples, title):\n",
    "        self.parameters = parameters\n",
    "        self.samples=samples\n",
    "        self.title = title\n",
    "\n",
    "\n",
    "    def __call__(self, network_information, output_information):\n",
    "        showAndSave.prefix='%s_%s_%s_ts_%d_bs_%d' %(self.title,\n",
    "            network_information.optimizer.__name__,\n",
    "            network_information.loss,\n",
    "            network_information.batch_size,\n",
    "            network_information.train_size)\n",
    "\n",
    "        get_network_and_postprocess(self.parameters, self.samples,\n",
    "                    network_information = network_information,\n",
    "                    output_information = output_information)\n",
    "\n",
    "training_sizes = [128, 256]\n",
    "for selection_type in selections.keys():\n",
    "    display(HTML(\"<h1>%s</h1>\" % selection_type))\n",
    "    \n",
    "    for selection in selections[selection_type]:\n",
    "   \n",
    "        display(HTML(\"<h2>%s</h2>\" % selection))\n",
    "        \n",
    "   \n",
    "\n",
    "        \n",
    "\n",
    "        number_of_widths = 4\n",
    "        number_of_depths = 4\n",
    "\n",
    "\n",
    "\n",
    "        for n, force_name in enumerate(force_names):\n",
    "            display(HTML(\"<h3>%s</h3>\" % force_name))\n",
    "            for train_size in training_sizes:\n",
    "                parameters = qmc_points\n",
    "                samples = forces[:, n+1]\n",
    "                title = '%s %s %s' % (selection_type, selection, force_name)\n",
    "                short_title = force_name\n",
    "                run_function = TrainingFunction(parameters=parameters,\n",
    "                    samples = samples,\n",
    "                    title = title)\n",
    "\n",
    "\n",
    "                optimizers = {\"SGD\": keras.optimizers.SGD}\n",
    "\n",
    "                losses = [\"mean_squared_error\"]\n",
    "\n",
    "                optimizer = 'SGD'\n",
    "                loss = losses[0]\n",
    "                tables = Tables.make_default()\n",
    "\n",
    "                network_information = NetworkInformation(optimizer=optimizers[optimizer], epochs=epochs,\n",
    "                                                         network=None, train_size=None,\n",
    "                                                         validation_size=None,\n",
    "                                                        loss=loss, tries=5, \n",
    "                                                        selection=selection)\n",
    "\n",
    "\n",
    "                title = '%s %s %s' % (selection_type, selection, force_name)\n",
    "                short_title = force_name\n",
    "                output_information = OutputInformation(tables=tables, title=title,\n",
    "                                                      short_title=title, enable_plotting=False)\n",
    "\n",
    "\n",
    "                selection_error, error_map = find_best_network_size_notebook(network_information = network_information,\n",
    "                    output_information = output_information,\n",
    "                    train_size = train_size,\n",
    "                    run_function = run_function,\n",
    "                    number_of_depths = number_of_depths,\n",
    "                    number_of_widths = number_of_widths,\n",
    "                    base_title = title,\n",
    "                    only_selection = False)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "batch_sizes=[train_size]\n",
    "train_sizes = [16, 32, train_size]\n",
    "\n",
    "optimizers = {\"SGD\": keras.optimizers.SGD,\n",
    "             \"Adam\": keras.optimizers.Adam}\n",
    "\n",
    "losses = [\"mean_squared_error\", \"mean_absolute_error\"]\n",
    "selections = ['mean', 'mean_train', 'mean_tail', 'prediction', 'train', 'ray_prediction']\n",
    "for selection in selections:\n",
    "    display(HTML(\"<h1>%s</h1>\" % selection))\n",
    "    for optimizer in optimizers.keys():\n",
    "        for loss in losses:\n",
    "            display(HTML(\"<h1>{} with {}</h1>\".format(optimizer, loss)))\n",
    "    \n",
    "            for batch_size in batch_sizes:\n",
    "                tables = Tables.make_default()\n",
    "                \n",
    "                for (n, f) in enumerate(force_names):\n",
    "                    seed_random_number(random_seed)\n",
    "                    network_information = NetworkInformation(optimizer=optimizers[optimizer], epochs=epochs, \n",
    "                                                             network=airfoils_network, train_size=train_size,\n",
    "                                                             validation_size=validation_size,\n",
    "                                                            loss=loss, \n",
    "                                                            large_integration_points=large_qmc_points,\n",
    "                                                            selection=selection, tries=10)\n",
    "                    \n",
    "                    output_information = OutputInformation(tables=tables, title=force_names[n],\n",
    "                                                          short_title=force_names[n], enable_plotting=True)\n",
    "                    showAndSave.prefix='airfoil_%s_%s_%s_%s_ts_%d_bs_%d' %(selection, optimizer, loss, f,batch_size, train_size)\n",
    "                    get_network_and_postprocess(qmc_points, forces[:,n+1], network_information = network_information,\n",
    "                        output_information = output_information)\n",
    "                \n",
    "                showAndSave.prefix='airfoil_%s_%s_%s_all_ts_%d_bs_%d' %(selection, optimizer, loss, batch_size, train_size)\n",
    "                tables.write_tables()\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As a function of training errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "epochs = 500000\n",
    "\n",
    "optimizers = {\"SGD\": keras.optimizers.SGD,\n",
    "             \"Adam\": keras.optimizers.Adam}\n",
    "loss = \"mean_squared_error\"\n",
    "optimizer='SGD'\n",
    "for n in range(len(force_names)):\n",
    "    f=force_names[n]\n",
    "    tables = Tables.make_default()\n",
    "    def run_function(network_information, output_information):\n",
    "        showAndSave.prefix='airfoil_convergence_%s_%s_%s_ts_%d_bs_%d' %(optimizer, loss, f, \n",
    "                                                                        network_information.batch_size,\n",
    "                                                                        network_information.train_size)\n",
    "        showAndSave.silent=True\n",
    "        print_comparison_table.silent = True\n",
    "        get_network_and_postprocess(qmc_points, forces[:,n+1], network_information = network_information,\n",
    "            output_information = output_information)\n",
    "        \n",
    "        showAndSave.prefix='airfoil_convergence_result_%s_%s_%s' %(optimizer, loss, f)\n",
    "        \n",
    "        \n",
    "    network_information = NetworkInformation(optimizer=optimizers[optimizer], epochs=epochs, \n",
    "                                                     network=airfoils_network, train_size=None,\n",
    "                                                     validation_size=None,\n",
    "                                                    loss=loss, \n",
    "                                                    large_integration_points=None,\n",
    "                                                    tries=5)\n",
    "            \n",
    "    output_information = OutputInformation(tables=tables, title=force_names[n],\n",
    "                                          short_title=force_names[n])\n",
    "    \n",
    "    plot_train_size_convergence(network_information,\n",
    "                               output_information, \n",
    "                               run_function,\n",
    "                               qmc_points.shape[0]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_information.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "epochs = 5\n",
    "\n",
    "optimizers = {\"SGD\": keras.optimizers.SGD,\n",
    "             \"Adam\": keras.optimizers.Adam}\n",
    "loss = \"mean_squared_error\"\n",
    "optimizer='SGD'\n",
    "selections = ['mean', 'mean_train', 'mean_tail', 'prediction']\n",
    "for selection in selections:\n",
    "    display(HTML(\"<h1>%s</h1>\" % selection))\n",
    "    for n in range(len(force_names)):\n",
    "        f=force_names[n]\n",
    "        tables = Tables.make_default()\n",
    "        def run_function(network_information, output_information):\n",
    "            showAndSave.prefix='airfoil_convergence_%s_%s_%s_%s_ts_%d_bs_%d' %(selection, optimizer, loss, f, \n",
    "                                                                            network_information.batch_size,\n",
    "                                                                            network_information.train_size)\n",
    "            showAndSave.silent=True\n",
    "            print_comparison_table.silent = True\n",
    "            get_network_and_postprocess(qmc_points, forces[:,n+1], network_information = network_information,\n",
    "                output_information = output_information)\n",
    "            \n",
    "            showAndSave.prefix='airfoil_convergence_result_%s_%s_%s_%s' %(selection, optimizer, loss, f)\n",
    "            \n",
    "            \n",
    "        network_information = NetworkInformation(optimizer=optimizers[optimizer], epochs=epochs, \n",
    "                                                         network=airfoils_network, train_size=None,\n",
    "                                                         validation_size=None,\n",
    "                                                        loss=loss, \n",
    "                                                        selection=selection,\n",
    "                                                        large_integration_points=None,\n",
    "                                                        tries=10)\n",
    "                \n",
    "        output_information = OutputInformation(tables=tables, title=force_names[n],\n",
    "                                              short_title=force_names[n])\n",
    "        \n",
    "        plot_train_size_convergence(network_information,\n",
    "                                   output_information, \n",
    "                                   run_function,\n",
    "                                   qmc_points.shape[0]\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
