{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../python')\n",
    "import time\n",
    "from plot_info import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import keras\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "qmc_points = np.loadtxt('../sobol_6_8000.txt')\n",
    "qmc_points = qmc_points[1:].reshape((8000,6))\n",
    "\n",
    "all_points = qmc_points.copy()\n",
    "forces = np.array(np.loadtxt('../force_6_params.dat'))\n",
    "\n",
    "plt.scatter(forces[:,1], forces[:,2])\n",
    "plt.xlabel(\"Lift\")\n",
    "plt.ylabel(\"Drag\")\n",
    "plt.show()\n",
    "\n",
    "N = min(qmc_points.shape[0], forces.shape[0])\n",
    "qmc_points = qmc_points[:N,:]\n",
    "forces  = forces[:N,:]\n",
    "\n",
    "permuted_indices = range(N)#np.random.permutation(N)\n",
    "qmc_points=qmc_points[permuted_indices,:]\n",
    "forces = forces[permuted_indices,:]\n",
    "input_size=6\n",
    "force_component = 1\n",
    "train_size=128\n",
    "validation_size=200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_network(parameters, data, *,train_size, validation_size, batch_size, title):\n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(input_size,)),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  loss='mean_squared_error')\n",
    "    x_train = parameters[:train_size,:]\n",
    "    y_train=data[:train_size]\n",
    "    \n",
    "    \n",
    "    x_val = parameters[train_size:validation_size+train_size,:]\n",
    "    y_val=data[train_size:train_size+validation_size]\n",
    "    epochs=500000\n",
    "    \n",
    "    training_start_time=time.time()\n",
    "    hist = model.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,shuffle=True, \n",
    "                     validation_data=(x_val, y_val),verbose=0)\n",
    "    training_end_time=time.time()\n",
    "    print(\"Training took {} seconds\".format (training_end_time-training_start_time))\n",
    "    \n",
    "    epochs_r=range(1, epochs)\n",
    "    plt.loglog(hist.history['loss'])\n",
    "    plt.title('Training loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('training_loss')\n",
    "    \n",
    "    plt.loglog(hist.history['val_loss'])\n",
    "    plt.title('Validation loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('validation_loss')\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.loglog(hist.history['loss'], label='Training loss')\n",
    "    plt.loglog(hist.history['val_loss'],label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training loss and validation loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('training_validation_loss')\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    x_test =  parameters[validation_size+train_size:,:]\n",
    "    y_test = data[train_size+validation_size:]\n",
    "    y_predict = model.predict(x_test)\n",
    "    \n",
    "    plt.title('Scatter comparision (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.scatter(y_test, y_predict)\n",
    "    plt.xlabel(\"Actual data\")\n",
    "    plt.ylabel(\"Predicted data\")\n",
    "    showAndSave(\"scatter_comparison\")\n",
    "    print(model.summary())\n",
    "    \n",
    "   \n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.LinearRegression()\n",
    "    coeffs = reg.fit(parameters[:train_size,:], y_train)\n",
    "    \n",
    "    evaluated_lsq = coeffs.predict(parameters)\n",
    "    plt.scatter(data, evaluated_lsq)\n",
    "    plt.title('Linear Least squares (%d samples)' % (train_size))\n",
    "    plt.xlabel(\"Actual data\")\n",
    "    plt.ylabel(\"Interpolated data\")\n",
    "    showAndSave(\"scatter_lsq_comparision\")\n",
    "    \n",
    "    \n",
    "    def myvar(x):\n",
    "        mean = np.sum(x)/x.shape[0]\n",
    "        var = np.sum((mean-x)**2)/x.shape[0]\n",
    "        return var\n",
    "        \n",
    "    def mymean (x): \n",
    "        return np.sum(x)/x.shape[0]\n",
    "    \n",
    "    variance_top = myvar(data)\n",
    "    print(\"variance single level = %f\" % variance_top)\n",
    "    predicted = model.predict(parameters)\n",
    "    predicted = predicted.reshape(parameters.shape[0])\n",
    "    variance_diff_ml = myvar(data - predicted)\n",
    "    \n",
    "    \n",
    "    print(\"variance diff ml = %f \" % variance_diff_ml)\n",
    "    print(\"speedup = %f\" % (variance_top/variance_diff_ml/2.))\n",
    "    print((data - evaluated_lsq).shape)\n",
    "    variance_diff_interpolate =myvar(data - evaluated_lsq)\n",
    "    print(\"variance_diff_interpolate = %f\" % variance_diff_interpolate)\n",
    "    \n",
    "    mean_qmc = np.mean(data)\n",
    "    print(\"mean_qmc = %f\" % mean_qmc)\n",
    "    mean_ml = np.mean(model.predict(parameters))\n",
    "    print(\"mean_ml = %f\" % mean_ml)\n",
    "    mean_few_qmc = np.mean(parameters[:train_size,:])\n",
    "    \n",
    "    print(\"mean_few_qmc = %f\" % mean_few_qmc)\n",
    "    predicted_all = model.predict(all_points)\n",
    "    predicted_all = predicted_all.reshape(all_points.shape[0])\n",
    "    print(predicted_all.shape)\n",
    "    mean_mlmlmc = mymean(predicted[:train_size]-data[:train_size]) + mymean(predicted_all)\n",
    "    \n",
    "    print(\"mean_mlmlmc = %f\" % mean_mlmlmc)\n",
    "    var_qmc = np.var(data)\n",
    "    print(\"var_qmc = %f\" % var_qmc)\n",
    "    var_ml = np.var(model.predict(parameters))\n",
    "    print(\"var_ml = %f\" % var_ml)\n",
    "    var_few_qmc = np.var(parameters[:train_size,:])\n",
    "    \n",
    "    print(\"var_few_qmc = %f\" % var_few_qmc)\n",
    "    print(parameters.shape)\n",
    "    \n",
    "    \n",
    "   \n",
    "    plt.hist(data,bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.title(\"Comparison QMC and DLQMC\\n%s\\nepochs=%d,batch_size=%d\"% (title, epochs,batch_size))\n",
    "    plt.hist(model.predict(parameters),bins=40,density=True,label='DLQMC (%d samples)' % train_size,alpha=0.5)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_ml_%s' % title)\n",
    "    \n",
    "    \n",
    "    plt.title(\"Comparison QMC with %d and QMC with %d samples\\n%s\" %(parameters.shape[0], train_size, title))\n",
    "    plt.hist(data,bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.hist(data[:train_size],bins=40,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_qmc_%s' % title)\n",
    "    \n",
    "    plt.title(\"Comparison QMC with least squares\\n%s\" % title)\n",
    "    plt.hist(data,bins=40,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "    plt.hist(evaluated_lsq,bins=40,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_lsq_%s' % title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.hist(data,bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.title(\"(coarse hist) Comparison QMC and DLQMC\\n%s\\nepochs=%d,batch_size=%d\"% (title, epochs,batch_size))\n",
    "    plt.hist(model.predict(parameters),bins=20,density=True,label='DLQMC(%d samples)' % train_size,alpha=0.5)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_ml_coarse_%s' % title)\n",
    "    \n",
    "    \n",
    "    plt.title(\"(coarse hist) Comparison QMC with %d and QMC with %d samples\\n%s\" %(parameters.shape[0], train_size, title))\n",
    "    plt.hist(data,bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.hist(data[:train_size],bins=20,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_qmc_coarse_%s' % title)\n",
    "    \n",
    "    plt.title(\"(coarse hist) Comparison QMC with least squares\\n%s\" % title)\n",
    "    plt.hist(data,bins=20,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "    plt.hist(evaluated_lsq,bins=20,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_lsq_coarse_%s' % title)\n",
    "    \n",
    "    samples = range(0,data.shape[0])\n",
    "    stats = {}\n",
    "    for stat in ['mean', 'var']:\n",
    "        stats[stat]={}\n",
    "        stats[stat]['sources']={}\n",
    "        if stat == 'mean':\n",
    "            stats[stat]['compute']=lambda x: sum(x)/x.shape[0]\n",
    "        else:\n",
    "            stats[stat]['compute']=lambda x: sum(x**2)/x.shape[0]-(sum(x)/x.shape[0])**2\n",
    "    \n",
    "     \n",
    "        stats[stat]['sources']['QMC']={}\n",
    "        stats[stat]['sources']['DLQMC'] = {}\n",
    "        stats[stat]['sources']['Least squares'] = {}\n",
    "        stats[stat]['sources']['DLbQMC'] = {}\n",
    "    \n",
    "        stats[stat]['sources']['QMC']['data']=array([stats[stat]['compute'](data[:k]) for k in samples])\n",
    "        stats[stat]['sources']['DLQMC']['data'] = array([stats[stat]['compute'](array(model.predict(parameters[:k,:]))) for k in samples])\n",
    "        stats[stat]['sources']['Least squares']['data'] = array([stats[stat]['compute'](evaluated_lsq[:k]) for k in samples])\n",
    "        \n",
    "        stats[stat]['sources']['DLbQMC']['data'] = [0]\n",
    "        \n",
    "        for k in samples[1:]:\n",
    "            if stat == 'mean':\n",
    "                mean = sum(model.predict(parameters[:train_size,:])-data[:train_size])/train_size +\\\n",
    "                sum(model.predict(parameters[:k,:]))/k\n",
    "                \n",
    "\n",
    "                stats[stat]['sources']['DLbQMC']['data'].append(mean)\n",
    "            elif stat=='var':\n",
    "                mean = sum(model.predict(parameters[:train_size,:])-data[:train_size])/train_size +\\\n",
    "                sum(model.predict(parameters[:k,:]))/k\n",
    "                \n",
    "                m2 = sum((data[:train_size])**2-(model.predict(parameters[:train_size,:]))**2)/train_size +\\\n",
    "                sum(model.predict(parameters[:k,:])**2)/k\n",
    "                \n",
    "\n",
    "                stats[stat]['sources']['DLbQMC']['data'].append(m2-mean**2)\n",
    "                \n",
    "        stats[stat]['sources']['DLbQMC']['data']=array(stats[stat]['sources']['DLbQMC']['data'])\n",
    "        \n",
    "        sources = stats[stat]['sources'].keys()\n",
    "        for source in sources:\n",
    "            \n",
    "            stats[stat]['sources'][source]['representative'] = stats[stat]['sources'][source]['data'][-1]\n",
    "            \n",
    "        \n",
    "       \n",
    "    \n",
    "        for source in stats[stat]['sources'].keys():\n",
    "            if 'DLbQMC' not in source:\n",
    "                plt.plot(samples, stats[stat]['sources'][source]['data'], label=source)\n",
    "        plt.xlabel('Number of samples ($J_L$)')\n",
    "        plt.ylabel('%s' % stat)\n",
    "        plt.title('%s as a function of number of samples used for evaluation\\n%s' % (stat, title))\n",
    "        plt.legend()\n",
    "        showAndSave('function_of_samples_airfoil_%s_%s'  % (stat, title))\n",
    "        stats[stat]['sources']['QMC_%d' % train_size] = {}\n",
    "        stats[stat]['sources']['QMC_%d' % train_size]['representative'] = stats[stat]['sources']['QMC']['data'][train_size]\n",
    "    sources = [source for source in stats['mean']['sources'].keys()]\n",
    "    sys.stdout.write(\"&\")\n",
    "    for source in sources:\n",
    "        if source != sources[-1]:\n",
    "            sys.stdout.write('\\\\multicolumn{2}{c|}{\\\\textbf{%s}} &&' % source)\n",
    "        else:\n",
    "            sys.stdout.write('\\\\multicolumn{2}{c|}{\\\\textbf{%s}} \\\\\\\\ \\n' % source)\n",
    "            \n",
    "    sys.stdout.write(\"&\")\n",
    "    for source in sources:\n",
    "        for stat in ['mean', 'var']:\n",
    "            if not (stat == 'var' and source ==  sources[-1]):\n",
    "                sys.stdout.write(\"%s &\" % stat)\n",
    "            else:\n",
    "                sys.stdout.write(\"%s \\\\\\\\ \" % stat)\n",
    "                \n",
    "            if stat == 'var' and source != sources[-1]:\n",
    "                sys.stdout.write(\"& \")\n",
    "            else:\n",
    "                sys.stdout.write(\" \")\n",
    "                \n",
    "    sys.stdout.write(\"%s & \" % title)\n",
    "    for source in sources:\n",
    "        for stat in ['mean', 'var']:\n",
    "            if not (stat == 'var' and source ==  sources[-1]):\n",
    "                sys.stdout.write(\"%.5f &\" % stats[stat]['sources'][source]['representative'])\n",
    "            else:\n",
    "                sys.stdout.write(\"%.5f \\\\\\\\ \\n\" % stats[stat]['sources'][source]['representative'])\n",
    "            \n",
    "            if stat == 'var' and source != sources[-1]:\n",
    "                sys.stdout.write(\"& \")\n",
    "            else:\n",
    "                sys.stdout.write(\" \")\n",
    "                \n",
    "                \n",
    "    #### Speedup\n",
    "    \n",
    "    baseline='QMC'\n",
    "    small_baseline = 'QMC_%d' % train_size\n",
    "    competitors = ['QMC_%d' % train_size, 'DLQMC', 'DLbQMC']\n",
    "    sys.stdout.write(\"&\")\n",
    "    for competitor in competitors:\n",
    "        \n",
    "        if competitor != competitors[-1]:\n",
    "            sys.stdout.write('\\\\multicolumn{2}{c|}{\\\\textbf{%s}} &&' % competitor)\n",
    "        else:\n",
    "            sys.stdout.write('\\\\multicolumn{2}{c|}{\\\\textbf{%s}} \\\\\\\\ \\n' % competitor)\n",
    "            \n",
    "    sys.stdout.write(\"&\")\n",
    "    for source in competitors:\n",
    "        for stat in ['mean', 'var']:\n",
    "            if not (stat == 'var' and competitor ==  competitors[-1]):\n",
    "                sys.stdout.write(\"%s &\" % stat)\n",
    "            else:\n",
    "                sys.stdout.write(\"%s \\\\\\\\ \" % stat)\n",
    "                \n",
    "            if stat == 'var' and competitor != competitors[-1]:\n",
    "                sys.stdout.write(\"& \")\n",
    "            else:\n",
    "                sys.stdout.write(\" \")\n",
    "                \n",
    "    sys.stdout.write(\"%s & \" % title)\n",
    "    \n",
    "    for competitor in competitors:\n",
    "        for stat in ['mean', 'var']:\n",
    "            \n",
    "            error = abs(stats[stat]['sources'][competitor]['representative']-stats[stat]['sources'][baseline]['representative'])\n",
    "            \n",
    "            error_base = abs(stats[stat]['sources'][small_baseline]['representative']-stats[stat]['sources'][baseline]['representative'])\n",
    "            \n",
    "            speedup = error_base/error\n",
    "            if not (stat == 'var' and competitor ==  competitors[-1]):\n",
    "                sys.stdout.write(\"%.5f &\" % speedup)\n",
    "            else:\n",
    "                sys.stdout.write(\"%.5f \\\\\\\\ \\n\" % speedup)\n",
    "            \n",
    "            if stat == 'var' and source != sources[-1]:\n",
    "                sys.stdout.write(\"& \")\n",
    "            else:\n",
    "                sys.stdout.write(\" \")\n",
    "    \n",
    "    \n",
    "    \n",
    "    for stat in ['mean', 'var']:\n",
    "        errors_qmc = []\n",
    "            \n",
    "        for k in samples[1:-2]:\n",
    "            errors_qmc.append(abs(stats[stat]['sources']['QMC']['representative']-\\\n",
    "                                      stats[stat]['sources']['QMC']['data'][k]))\n",
    "        plt.loglog(samples[1:-2], errors_qmc, label='QMC error')\n",
    "        \n",
    "        for competitor in ['DLbQMC', 'DLQMC', 'Least squares']:\n",
    "            error = abs(stats[stat]['sources'][competitor]['representative']-stats[stat]['sources'][baseline]['representative'])\n",
    "            \n",
    "                \n",
    "            \n",
    "            plt.loglog(samples[1:-2], error*ones_like(samples[1:-2]), '--', label='%s error' % competitor)\n",
    "        \n",
    "        plt.xlabel('Number of samples for QMC')\n",
    "        plt.ylabel('Error')\n",
    "        plt.title('Error for %s compared to QMC' % stat)\n",
    "        showAndSave(\"error_evolution_%s\" % stat)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "    ###### Speedup Wasserstein\n",
    "    N_wasser = 2**(int(log2(data.shape[0])))\n",
    "    qmc_upscaled = repeat(data[:train_size], N_wasser/train_size)\n",
    "    \n",
    "    wasser_qmc_qmc = scipy.stats.wasserstein_distance(data, qmc_upscaled)\n",
    "    wasser_qmc_ml = scipy.stats.wasserstein_distance(data, reshape(model.predict(parameters), data.shape))\n",
    "    wasser_qmc_lsq = scipy.stats.wasserstein_distance(data, evaluated_lsq)\n",
    "    \n",
    "    speedup_qmc = wasser_qmc_qmc / wasser_qmc_qmc\n",
    "    speedup_ml =  wasser_qmc_qmc / wasser_qmc_ml \n",
    "    speedup_lsq = wasser_qmc_qmc / wasser_qmc_lsq\n",
    "    \n",
    "    print(\"\\\\toprule\")\n",
    "    print(\"&DLQMC & Least squares & QMC 128\\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    print(\"{} & {} & {} & {}\".format(title, speedup_ml, speedup_lsq, speedup_qmc))\n",
    "    \n",
    "    \n",
    "    errors_qmc = []\n",
    "            \n",
    "    for k in range(1, int(log2(data.shape[0]))):\n",
    "        qmc_upscaled = repeat(data[:int(2**k)], N_wasser//int(2**k))\n",
    "        errors_qmc.append(scipy.stats.wasserstein_distance(data, qmc_upscaled))\n",
    "        \n",
    "    samples_wasser = 2**array(range(1, int(log2(data.shape[0]))))\n",
    "    plt.loglog(samples_wasser, errors_qmc, label='QMC error')\n",
    "    \n",
    "    plt.loglog(samples_wasser, wasser_qmc_ml*ones_like(samples_wasser), '--', label='DLMC error')\n",
    "    plt.loglog(samples_wasser, wasser_qmc_lsq*ones_like(samples_wasser), '--', label='LSQ error')\n",
    "    \n",
    "    plt.xlabel('Number of samples for QMC')\n",
    "    plt.ylabel('Error (Wasserstein)')\n",
    "    plt.title('Error (Wasserstein) for %s compared to QMC' % stat)\n",
    "    showAndSave(\"error_evolution_wasserstein\")\n",
    "            \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "batch_sizes=[16, 32, train_size]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for (n, f) in enumerate(force_names):\n",
    "        showAndSave.prefix='airfoil_%s_ts_%d_bs_%d' %(f,batch_size, train_size)\n",
    "        network= get_network(qmc_points, forces[:,n+1], train_size=train_size, validation_size=validation_size,\n",
    "                        batch_size=batch_size, title=f)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_dual(parameters, data, *,train_size, validation_size, batch_size, title, names):\n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(input_size,)),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(data.shape[1])\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  loss='mean_squared_error')\n",
    "    x_train = parameters[:train_size,:]\n",
    "    y_train=data[:train_size,:]\n",
    "    \n",
    "    \n",
    "    x_val = parameters[train_size:validation_size+train_size,:]\n",
    "    y_val=data[train_size:train_size+validation_size,:]\n",
    "    epochs=500000\n",
    "    \n",
    "    training_start_time=time.time()\n",
    "    hist = model.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,shuffle=True, \n",
    "                     validation_data=(x_val, y_val),verbose=0)\n",
    "    training_end_time=time.time()\n",
    "    print(\"Training took {} seconds\".format (training_end_time-training_start_time))\n",
    "    \n",
    "    epochs_r=range(1, epochs)\n",
    "    plt.loglog(hist.history['loss'])\n",
    "    plt.title('Training loss (%d samples, batch size: %d, output_size: %d)\\n%s' %(train_size, batch_size, data.shape[1], title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('training_loss_dual')\n",
    "    \n",
    "    plt.loglog(hist.history['val_loss'])\n",
    "    plt.title('Validation loss (%d samples, batch size: %d, output_size: %d)\\n%s' %(train_size, batch_size, data.shape[1], title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('validation_loss_dual')\n",
    "    \n",
    "    \n",
    "    x_test =  parameters[validation_size+train_size:,:]\n",
    "    y_test = data[train_size+validation_size:,:]\n",
    "    y_predict = model.predict(x_test)\n",
    "    \n",
    "    for c in range(data.shape[1]):\n",
    "        plt.title('Scatter comparision %s (%d samples, batch size: %d)\\n%s' %(names[c], train_size, batch_size, title))\n",
    "        plt.scatter(y_test[:,c], y_predict[:,c])\n",
    "        plt.xlabel(\"Actual data\")\n",
    "        plt.ylabel(\"Predicted data\")\n",
    "        showAndSave(\"scatter_comparison_dual_%s\" % names[c])\n",
    "        print(model.summary())\n",
    "    \n",
    "   \n",
    "    from sklearn import linear_model\n",
    "    \n",
    "      \n",
    "    for c in range(data.shape[1]):\n",
    "        reg = linear_model.LinearRegression()\n",
    "        coeffs = reg.fit(parameters[:train_size,:], y_train[:,c])\n",
    "        evaluated_lsq = coeffs.predict(parameters)\n",
    "        plt.scatter(data[:,c], evaluated_lsq)\n",
    "        plt.title('Linear Least squares %s (%d samples)' % (names[c], train_size))\n",
    "        plt.xlabel(\"Actual data\")\n",
    "        plt.ylabel(\"Interpolated data\")\n",
    "        showAndSave(\"scatter_lsq_comparision_dual_%s\" % names[c])\n",
    "    \n",
    "   \n",
    " \n",
    "        plt.hist(data[:,c],bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.title(\"Comparison QMC and DLMC %s\\n%s\\nepochs=%d, batch_size=%d\"% (names[c], title, epochs,batch_size))\n",
    "        plt.hist(model.predict(parameters)[:,c],bins=40,density=True,label='DLMC(%d samples)' % train_size,alpha=0.5)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_ml_dual_%s' % names[c])\n",
    "        \n",
    "        \n",
    "        plt.title(\"Comparison QMC with %d and QMC with %d samples\\n%s\\n%s\" %(parameters.shape[0], train_size, names[c], title))\n",
    "        plt.hist(data[:,c],bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.hist(data[:train_size,c],bins=40,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_qmc_dual_%s' % names[c])\n",
    "        \n",
    "        plt.title(\"Comparison QMC with least squares %s\\n%s\" % (names[c], title))\n",
    "        plt.hist(data[:,c],bins=40,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "        plt.hist(evaluated_lsq,bins=40,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_lsq_dual_%s' % names[c])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.hist(data[:,c],bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.title(\"Comparison QMC and DLMC %s\\n%s\\nepochs=%d, batch_size=%d\"% (names[c], title, epochs,batch_size))\n",
    "        plt.hist(model.predict(parameters)[:,c],bins=20,density=True,label='DLMC(%d samples)' % train_size,alpha=0.5)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_ml_dual_%s_coarse' % names[c])\n",
    "        \n",
    "        \n",
    "        plt.title(\"Comparison QMC with %d and QMC with %d samples\\n%s\\n%s\" %(parameters.shape[0], train_size, names[c], title))\n",
    "        plt.hist(data[:,c],bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.hist(data[:train_size,c],bins=20,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_qmc_dual_%s_coarse' % names[c])\n",
    "        \n",
    "        plt.title(\"Comparison QMC with least squares %s\\n%s\" % (names[c], title))\n",
    "        plt.hist(data[:,c],bins=20,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "        plt.hist(evaluated_lsq,bins=20,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_lsq_dual_%s_coarse' % names[c])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        samples = range(0,data.shape[0])\n",
    "        stats = {}\n",
    "        for stat in ['mean', 'var']:\n",
    "            stats[stat]={}\n",
    "\n",
    "            stats[stat]['sources']={}\n",
    "            if stat == 'mean':\n",
    "                stats[stat]['compute']=lambda x: sum(x)/x.shape[0]\n",
    "            else:\n",
    "                stats[stat]['compute']=lambda x: sum(x**2)/x.shape[0]-(sum(x)/x.shape[0])**2\n",
    "            \n",
    "            stats[stat]['sources']['QMC']={}\n",
    "            stats[stat]['sources']['ML'] = {}\n",
    "            stats[stat]['sources']['Least squares'] = {}\n",
    "    \n",
    "            print(parameters.shape)\n",
    "            print(array(model.predict(parameters[:10,:])).shape)\n",
    "            print(array(model.predict(parameters[:1,:])).shape)\n",
    "            print(array(model.predict(parameters[:0,:])).shape)\n",
    "            stats[stat]['sources']['QMC']['data']=array([stats[stat]['compute'](data[:k,c]) for k in samples])\n",
    "            \n",
    "            stats[stat]['sources']['ML']['data'] = [0]\n",
    "            for k in samples[1:]:\n",
    "                stats[stat]['sources']['ML']['data'].append(stats[stat]['compute'](array(model.predict(parameters[:k,:]))[:,c]))\n",
    "                \n",
    "          \n",
    "            stats[stat]['sources']['Least squares']['data'] = array([stats[stat]['compute'](evaluated_lsq[:k]) for k in samples])\n",
    "            \n",
    "            \n",
    "            for source in stats[stat]['sources'].keys():\n",
    "                plt.plot(samples, stats[stat]['sources'][source]['data'], label=source)\n",
    "            plt.xlabel('Number of samples ($J_L$)')\n",
    "            plt.ylabel('%s' % stat)\n",
    "            plt.title('%s as a function of number of samples used for evaluation' % stat)\n",
    "            showAndSave('function_of_samples_airfoil_dual_%s_%s' % (names[c], stat))\n",
    "        \n",
    "    \n",
    "    return network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "batch_sizes=[16, 32, train_size]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    showAndSave.prefix='airfoil_ts_%d_bs_%d_dual' %(batch_size, train_size)\n",
    "    network= get_network_dual(qmc_points, forces[:,1:], train_size=train_size, validation_size=validation_size,\n",
    "                        batch_size=batch_size, title=\"One network for both variables\",names=force_names)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
