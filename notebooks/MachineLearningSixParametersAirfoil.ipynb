{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X+UXOWZ2Pnv09UlqVrYKoE1WSgkpLExCjJIMjKQUdYb4QUx1oC0/LDAdoxznHBmE3YP2OldkSGWxJAgj+JAJuP8YMfe9RgM4pd7hOWJ7LGUTIItguSWrGmMxuKHhUqcWLZUmpG6hKq7n/2j6pZu3br31r1Vt3509/M5h0N31a2qt27Dfe77vs/7vKKqGGOMMa3q63YDjDHGTA0WUIwxxiTCAooxxphEWEAxxhiTCAsoxhhjEmEBxRhjTCIsoBhjjEmEBRRjjDGJsIBijDEmEf3dbkAnfeADH9CFCxd2uxnGGDOp7Nu371eqOq/RcdMqoCxcuJC9e/d2uxnGGDOpiMgvohxnQ17GGGMSYQHFGGNMIiygGGOMSYQFFGOMMYmwgGKMMSYRFlCMMcYkwgKKMcaYRFhAMcYYkwgLKMYYYxJhAcUYY0wiLKAYY4xJhAUUY4wxibCAYowxJhEWUIwxxiTCAooxxphEWEAxxhiTCAsoxhhjEmEBxRhjTCK6GlBE5GYROSQih0Vkg8/zHxeRn4jImIjc4Xp8mYj8WERGROSnIrK+sy03xhjj1bWAIiIp4GvAbwNXAneLyJWew44Anwe+7Xl8FPicqi4BbgYeF5Fse1tsjDEmTH8XP/ta4LCqvgkgIs8Aa4HXnANU9e3KcxPuF6rqX7l+PiYivwTmAYX2N9sYY4yfbg555YB3XL8frTwWi4hcC8wA3kioXcYYY5rQzYAiPo9prDcQuRj4FvAPVHUi4Jh7RWSviOw9fvx4E800xhgTRTcDylFgvuv3S4FjUV8sIu8HdgAPqeqeoONU9QlVXaGqK+bNm9d0Y40xxoTr5hzKq8DlIrIIyAN3AZ+O8kIRmQF8B/gTVX2ufU00xpjJ4aGhgzz9yjuMq5IS4e7r5vPIuqs62oau9VBUdQy4D9gJ/Ax4VlVHRORhEbkVQEQ+JiJHgTuB/ygiI5WXfwr4OPB5Edlf+WdZF76GMcZ03UNDB3lyzxHGtTxrMK7Kk3uO8NDQwY62Q1RjTVtMaitWrNC9e/d2uxnGGJOoDz74vWowcUuJ8Majn2z5/UVkn6quaHScrZQ3xphJzi+YhD3eLhZQjDFmkkuJX9Js8OPtYgHFGGMmubuvmx/r8XbpZpaXMcaYBDjZXN3O8rJJeWOMMaFsUt4YY0xH2ZCXMcZMEkPDebbuPMSxQpFLshkGV1/BuuWxSyC2jQUUY4yZBIaG8zz44kGKpXEA8oUiD75YXrjYK0HFhryMMWYS2LrzUDWYOIqlcbbuPNSlFtWzHooxxjTQC0NNxwrFSI93s60WUIwxJkSvDDVdks2Q9wkql2Qz1Z+73VYb8jLGmBCtDjUNDedZuWUXizbsYOWWXQwN55tqx+DqK8ikUzWPZdIpBldfkVhbW2U9FGOMCRF1qMlPkj0G5/iw4axW2poECyjGGBMiylBTkKAew5eePQA0F1TCXtNKW5NgQ17GGBPCb6hJKPc2Gg1hBfUMxlV58MWDTQ9/BYkyLNZO1kMxxpgQ7qGmfKGIAE7BqkZDWEE9Bjg/t+F+XasZWlGGxdrJankZY0xEK7fs8g0QuWyGlzfcUPe4dw7FS4C3tqwJPDaTTvHobVd1feGi1fIyxpiExZ30Xrc8x6O3XRW4L4l7bqPbGVpJsIBijDERBU1uh016r1ue46ufWtpwbqPbGVpJ6GpAEZGbReSQiBwWkQ0+z39cRH4iImMicofnuXtE5OeVf+7pXKuNMb0kqXUeUTQ76e30VHLZDEJ5iMw7lNVMsOo1XZuUF5EU8DXgRuAo8KqIbFfV11yHHQE+D/xTz2svBDYCKyjPj+2rvPZkJ9pujOkNnV4ZHnfSO84k++DqK3znUDqVoZWEbmZ5XQscVtU3AUTkGWAtUA0oqvp25bkJz2tXAz9Q1ROV538A3Aw83f5mG2N6Rdi8Q7smsr1rQZwekjdoxA123c7QSkI3A0oOeMf1+1HguhZeO3nOujEmkkZ3+N2edwgLGs0Eu0YLF3tdNwOKX9pD1BzmyK8VkXuBewEWLFgQ8e2NMd0W5Q6/2yvDw4JGWLDrherF7dDNSfmjwHzX75cCx5J+rao+oaorVHXFvHnzmmqoMabzoqTRdntleFjQCApq2YE0D754kHyhiHI+ULYzmaBTuhlQXgUuF5FFIjIDuAvYHvG1O4GbRGSuiMwFbqo8ZoyZIqIMZ0XJnmqnsMysoGCnyqRfbxKka0NeqjomIvdRDgQp4BuqOiIiDwN7VXW7iHwM+A4wF7hFRDar6hJVPSEiv085KAE87EzQG2OmhqjDWd2cdwjLzAqaZH9g237f95pM602CWOkVY0xP6uVSJG5x50Pilm/pBVFLr1hxSGNMT5osabRxe0hTYb1JEAsoxpie1exwVi9nUU2WQNkMCyjGmCml2/uqRzHZ15sEsYBijJlS4i4oHBrOs2n7CIViCYC5A2k23rJkSl7w280CijFmSgna0Mrv8aHhPIPPHaA0cT456eRoicHnz2/R2+zwWS8Pu7WLBRRjTFe064KbEmHcJ3vVb0+SrTsP1QQTR2lcq+tC4gyfOd/JG7zyhWJNkJqqbD8UY0zHOfMc7Vgt7hdMgh4PW/txrFCMtemV+zv5KY0rm18aCWv6pGc9FGNMx7WzSnAuYEFkLpup6xVlB9KcHC35vk/YfvB+j2/aPhK41a8j6LNgagyRWQ/FGNNx7awSHFTyZNXieXW9otNnx+jzKTXbJ+X3Cdq61/v40HC+OqnfjKHhPIPPH6hp2+DzByZdfS8LKMaYjmvn7oRB9b12v368rgdRmlBm9tdfBlOVKBN1+CxOHS6/ILH5pRFK47XvORmHyGzIyxjTcasWz+PJPUd8Hw8TdVjIb51HUA2tYsm7f1/5Yv573zkYOMGf8wS+OD0rv2G9oKGwsCGyXmQBxRjTcbtfPx7rcWh9wWLYnIifM+f850PcZVKcABenIuJUKAIZxIa8jDEd18wcSpyMKz9BcytzB9KRXg/luROnOGWjrC7/2Rf/Yb1sxr8NQY/3KgsoxpiOa2YOpdWJ/KC5lY23LIn0eoAJ1ZpaXEFZXblshs9cvyDy5l+bbl1C2pMdkO4TNt0avW29wIa8jDEd10zF3SS2+w2qoeUuvRLG/VlBgUygWoZ+xWUX1sz5rFo8j607D/HAtv01c0BTpWCkBRRjTMc1cwFtZ9n3TbcuqXtvL+9nBQU4pbzniTdYNJoDmgoFI22DLWNMzwkq2Ajtu4v3ZpCtWjyP3a8fD/wsvw3AvNyFJifjxloO22DLGDMphRVs3HrH0kQvvq2sTnf3soIm5k+Olqq9kHYu5uwV1kMxxvSUoDt5SPZuPskthhdt2BGaOpwS4X2z+n3nabKZNLNn9vf03EnUHkpXs7xE5GYROSQih0Vkg8/zM0VkW+X5V0RkYeXxtIh8U0QOisjPROTBTrfdGNMejQo2JqXVNGS3OQ3Se8dVOXNuzDeT68y5sbYUyeyGrg15iUgK+BpwI3AUeFVEtqvqa67DvgCcVNUPichdwFeA9cCdwExVvUpEBoDXRORpVX27s9/CGJO0sAWIUTK6hobzbH5ppLrKPJtJs+nW+g2zmh2C8ptrOXNurGG7SuPK3IE0AzPO90ZGz43VrYZPqkhmN3RzDuVa4LCqvgkgIs8AawF3QFkLbKr8/DzwRyIilBMpZotIP5ABzgF/3aF2G2PaaHD1FXxx2368BVHSKWmY0eUUWXTXxSoUSww+d4C9vzhRM8k+J5P2HYIKC1p+mVpP7TkSeaV8YbTE8Jdvqv6+aMMO3+Mm67xKNwNKDnjH9ftR4LqgY1R1TEROARdRDi5rgXeBAeABVT3h9yEici9wL8CCBQuSbL8xpkV+k+IAqZQw4SmWuP5j8xvetfsVWYRyEUh37bB8oUg6JaT7pGby30kNDmrXl549UFfbK84sdHYgzcotuxqWz0+iSGY3dDOg+FUm8P5tgo65FhgHLgHmAv9VRP7c6e3UHKz6BPAElCflW2qxMSYxQesyZqX7fIOCU+crKDNraDgfq5ii3xCUEzi87Rp8/gBocPXhKNIp4fTZ80Nc+UKRdJ+QTknN901qbU03dDOgHAXmu36/FDgWcMzRyvDWHOAE8GngP6lqCfiliLwMrADqAooxpjcFTYoHres4ViiGLg5sZjL95Gipuk7EsXLLrvoy9z4BLo6UCLNn1Gd5lSZ0UmR5RdXNgPIqcLmILALywF2UA4XbduAe4MfAHcAuVVUROQLcICJPUh7yuh54vGMtN8a0LO48wSXZTGhmVrPzDt6KxUnPXzipyEHl808VS+zfeJPvc5NN19KGVXUMuA/YCfwMeFZVR0TkYRG5tXLY14GLROQw8EXASS3+GnAB8JeUA9P/q6o/7egXMMZUDQ3nWbllF4s27GDlll2R0l6D5gmymXRgUcWgi32+UGyYuhvEmyqcxPyFs6OjU4By3fJcWzcV6xVdXYeiqt9T1Q+r6gdV9V9UHvuyqm6v/HxWVe9U1Q+p6rXOHImqnq48vkRVr1TVrd38HsZMZ+4y7nHWUgSVk9906xLfqsBhF2XAd51HVO5A5dcuZwI/CgG++qml5LIZjhWKbN15qJx9FvB9J+t8iR9bKW+MaUkrNarilj5pVD/LO8nurcd15r0x31Rhb1uDsrzcjwW9VzaT5r2xCd8V+N73mCzzJVbLyxiTOL8LbdAixCi7I8apsOt8dlgxRmedh3PsU3uOcEk2w2Prl9VsitWoYrFfu7w9rt9ZejEv7MvXtccvyDjDai9vuGFSBJBmWQ/FGBNJ0MX4vbFxJnwuIykR3nj0k9XXtnJnHqWyL5R7Gn5l7p3V0LkIVYTjfPfbr8nx3QPvRtpLRYC3tqxpeFwvsh6KMdNcqxdxr6AMqyDjqqzcsotVi+fV3MnH3Qs+6LO9nJ6G37FOvMsXirywLx+7AGTQd//2K0d8g6mfqTT5HsQCijFTUKPNnJrRTDptUGmSYmmcB7btZ/NLIxRGSw0DXthnC9S8Pig91/3ZYbWynECcLxRJiYQuZowaTKba5HsQ21PemCkoyUq6jjhpvm5B11ylvLAwSmZY2N29NxhF6QkEBSh3xhq0tjLe4c5Sm+osoBgzBbVjM6coab6tCAt4fp/t8AajsGMd7qDjXkPzpWcPNBxai+Px9cum/ES8mwUUY6agdiyiW7c8F7g+ZN3yHC9vuKHloBIU8Nyf7adYGmfT9pHqsbdfk/MtBAi1w0/eNTRJ9EgccwfS0yaQOGwOxZgpyC/TKYlx/EZpvqsWz4tVzt3LG/D8Egse2Lbf9/0LxRJDw3nWLc+x+/XjgW24/Zrz3yHKZH8zMukUG29Zkvj79jrroRgzBYX1JtplaDjPC/vyTQcTb8ALWoGfHQguseIMmYUN7bmrFkdZKxOV0yOaTnMmXtZDMWaKirNoMAmt3O2nROouwkGJBTP7g++DnUAStuuju2pxEnKTaMV7u1kPxRiTiEYT/iIwkK6/5GTSKb76qaWRt+g9VSwxN6CX4gyZDa6+InAOJahqcbWdAa/zk82ka/ZjiVsgc6qxgGLMNNOuC1+jCX9VGC3Vbuw7dyAdODwU9H59IpwcLdVd+N1DZuuW5/itD15Y99pGVYsh3g6MhWKJB188yENDB5sqkDnVWEAxZhJpNRjEqQwc97MGV18Ru9rvwIz+wKGioPRfJxNLCZ63GBrO85Mjp+pe66QmB5W6z2Uzgb2fIMXSOE+/8k7i634mIwsoxkwSzZaJd4u64LHpz4pZPT6sp+BNLHD2GHFz6nN513qEDWnlC0XfUvdO7+VsE/NAQenGSW/W1esiTcqLyBd9Hj4F7FPV8DoHxphEhAWDqBPCYRtUrdyyq6Y0e9zP2rrzUOytcv2GtYJqkC3asCOw7V6NLuTu/eSdEivF0jibXxqh6BmWiyKoRMt0qN/lFjXLa0Xln5cqv6+hvFPi74rIc6r6B+1onDHmvCRWvwdlPwnnL8xhqbRhn9XM3fjg6itqAkh2IM3ps2OUKkWy3DXIwtrurD9xhGV5OZz95N3rdU6OhlcNTvcJSO0e807VYW8p++lSv8stakC5CPioqp4GEJGNwPPAx4F9gAUUY9os6CIZ5y44rLR71DbEbV+QPoH7t+2v+Xy/C7rTMwpa1KicX3/iDkzpPqkGJj8ClR5JtCEuEdh659Kaz3H3oFZcduGk3DwrSZH2QxGRnwFLVfVc5feZwH5V/dsiMqyqy9vczkTYfihmMgvakyPuIjrvkFLUINDos6LuWdKsXIO2ZtKpms9Op4T+PmlqCMvPZN7PpFVJ74fybWCPiPxp5fdbgKdFZDbwWpNtRERuBv4NkAL+WFW3eJ6fCfwJcA3wa2C9qr5dee5q4D8C7wcmgI+p6tlm22JMr3OXC2nlLti74DFoC18or7M4VWxcXt7dvs0vjYQOHTUqCR8kXygG9qacORC30rgykUwsAabffEgzIu/YKCIrgJWUA/V/U9WWbvVFJAX8FXAjcJTynMzdqvqa65h/DFytqr8rIncB/5uqrheRfuAnwN9X1QMichFQUNXQWyProRhTb2g4H1gfK5tJM3tmf6wAFhag5g6kKVRK1iel0dBWEprpCU4lUXsokdOGKwHkaeBF4JcisqCF9gFcCxxW1TcrQ2nPAGs9x6wFvln5+XngEyIiwE3AT1X1QKVtv24UTIwx/tYtzwVe4AvFUuTUYWfdStiwlGrjO/10SsgGrBPxJQQe75dqHONtq2b5rPA39SKdJRG5VUR+DrwF/JfKv/+sxc/OAe+4fj9aecz3GFUdo5yqfBHwYUBFZKeI/ERE/q+Qtt8rIntFZO/x48dbbLIxvSnqIsSg46KWnQ9arOfdmCrIqWLJd8Gie4Hi1juWsn/jTZHbVBpXRPDdq+Xu6+bHXRoDlHs9/anzrzw5WpqWK9/jijqH8vvA9cCfq+pyEVkF3N3iZ/v9nb03SkHH9AN/F/gYMAr8sNIl+2HdwapPAE9AecirpRYb04OibvcbdNzeX5zgzHtjkT/PLz04amHIvkqP4dHbrmo4F+SXkRbEO2fjLtj45J4jDV8P57PdctkMo+fG6t7TvQ4naK3MdBc1oJRU9dci0icifaq6W0S+0uJnHwXmu36/FDgWcMzRyrzJHOBE5fH/oqq/AhCR7wEfBeoCijGTWZQLV9QFj0HH+V1wZ89IMVoax2+K9ZJspulMsXFVHnzxII/edhUvb7gh9Fin7fc32CPez6rF86qvb5QdBuW5nY23LKm+JmgRpbtScaMAPh1FHRgsiMgFwF8AT4nIvwGi39L4exW4XEQWicgM4C5gu+eY7cA9lZ/vAHZpOYtgJ3C1iAxUAs3/QgvZZsb0oqjlT6IueIyz8PDMOf9gkkmnWLV4Xl274gwrFUvj3L9tPyu37OKhoYOBQ3VO0GrG06+cH02PsrhwYEbtvXXYjpdRy9dMR1EDylrKQ0sPAP8JeINy6nDTKnMi91EODj8DnlXVERF5WERurRz2deAiETkMfBHYUHntSeBfUw5K+4GfqKr/LYUxk1TUC1fU7X5bTXt19izZ/frxuna5CzU6Gu3rni8UeXLPEd+A2WhOplEAc6clr1uea1jwMcq+9I0qFU+3ul1+GgaUSnrvn6rqhKqOqeo3VfUPVfXXrX64qn5PVT+sqh9U1X9ReezLqrq98vNZVb1TVT+kqteq6puu1z6pqktU9SOqGjgpb8xkFfXCFXbxc1u1eF5L7ZlQZd3yXGC7lPNZVSkRbr8mF3uPeSdgNpqT+dBvzA59b29218ZbljQMcN5g7d7Iy11mP2oAn44aBpRKOu6oiMzpQHuMMRVRL1xRt/t1tr5ttT1B7RLO9wzGVXlhX55Vi+fFLml/rFBseLf/81+eCZ0XGVdl4YYdfPDB7/HQ0MG6cxT22U7vqFA8Pyl/1rXaPmoAn46iTsqfBQ6KyA+AM86Dqvp/tqVVxhjfLKegC1eU7X6jDsn0AamU1BVAdD43aj2wYmmc7x54N3ZJeydgJbHf+7hqNengkXXng2zQehkR//pe7iSHpCoWTEVRA8qOyj/GmA7xXriyA2lU4YFt+6vFEuNcxIKysfxWw7s/1++COSvdV73oZjPpmrt5t6DHg7gDVzPZXUGefuUdHll3VfX3wdVXMPj8gbpy+xMaXHHYHZCjBPDpKE7plXkAqjppVwda6RUzWYUVhoRod8tRi0uGpSoHvcfM/r7YwcMrJVKzt/zyh7/fsJx8HDnPd1m2+fux2uxs5DUdJVIcslLmZCPlbCwB+kRkDPi3qvpwIi01xjQUlPG1+aURzpYmatZEPLBtP/dv2193AY0yVNNojUVQO2al++pqaqX7hAtm9UcOCu+b1c/eX5xg0/aR2MEpSgl+73c5FeMzbI4kmkZDXvdTLgj5MVV9C0BEfhP49yLygKo+1u4GGmOC5z/8LtbOhdVvwV2joZpGiyTD2pFOeSZLBNZcfXHdxlNBCsVS6Kp2p0pxNpOmND7BmXPn37M8BNe4tLD7u4QtyGymKKZpnOX1OcoVgN9yHqik7n628pwxpgOaTUmNu+Au6ALrBJKgdqRE6uYjSuPK7teP8+htV/muA4kzV5/LZnjj0U/y+PplvDdWG0yAWHueON9lcPUVvhlo6ZSw6dYlvLzhBt7asqZuv3oTrFFASTvlTdwq8ygxyoEaY1oRlKoapSpvvpIK28jQcD7wIu8EkqB2BO1vcqxQZN3yHMNfvonH1y+rSW2OU1jPCXRRa4aFcb7LuuU5tt65tOYczh1Is/WOpRZAmtRoyOtck88ZYxLknf+Yk0kjUh5qijJ/cP+2/Wx+aaSmXpXX1p2HfN9HOF++JGgeZuvOQw23J3YPtz00dDBy0UY4v1AxidXo7rkQy9ZKVqOAslRE/trncQFmtaE9xpgAzsXPO3HulD1x/9uPU4LdeS+vsBXw7uODLsJ+abhn3htjaDhfc3zcYALnF0zG3bfeK5tJWwBpo9AhL1VNqer7ff55n6rakJcxXeC38M4pu/7Y+mWhr3XPqXj3RpkTMHwWuXyKTyQrFOv3EXEXbowq5xpyq5v8jyiTTrHp1iVNvdZEE3VhozGmi5y1IWF35858RZTjhobzDD53oJrmG3R81HTZrTsPBW7D6y2lH3c/+XSfMHpujEUbdjAnk2a8ie1+vSnUDtvXJFkWUIzpYUPDeTa/NBJpLYdSLimyavG80FTdS7IZNm0fabgPu3ePkDCN5jbczzvpv1GNq1a/f5z1Kd6Fkm5+59WbZm3BJj7bKNmYHuXMlcRZLZ4vFHlhX57br8n5ZoA5PY4oF+aznlTcsG2GG6U1u5+/+7r5IUfWa6JDUnmdhlYM8DuvTm8q6l40ppYFFGN6VLMpssXSOLtfP87+jfWpurdfk4u8LqVYGmfT9hGg8WZfqxbPC0w5TqeEM++NVQPRissujP2dmuHsLOkNgo3O67FC0TbRapINeRnTo1pJkXVe687I8qvD1UihWAq8CLsvsC/sy/tml80dSHP67Fi1R+QeVmq3hRdlfMvINPr+czJp20SrSdZDMaZHtbJhk99rm+3xbH5pJHQFfdD75rIZBmb0183VtLowEWAg3VftdX32+gVk0vWXsh+9ccI3CEqDJDGR6HvRmFoWUIzpUa2kyOYLRRZu2MGyzd+vDkuF3V2H7YEVNodzSTYT+L75QjGRPU38jJYmqhPlj6y7igtnz6w7JmjqRZXQ81oYLdkmWk3qakARkZtF5JCIHBaRDT7PzxSRbZXnXxGRhZ7nF4jIaRH5p51qszEdFXFCOujyWCiWGHzuAEPD+cC761w2w5uPrmm477qXc4Ht1l27ex4n7lDU7Bn9ddsEOy7JZiLvgmlqdS2gVPaq/xrw28CVwN0icqXnsC8AJ1X1Q8BjwFc8zz8G/Fm722pMJzkTyfdv2++b2pvNpGsudI+vX8ZbW9YELkAsTWh1Q66wu+41V18cq2CjM4eyavG8hvu1t4uTONDXaBzL41SxxFc/tTT0fKxbnrMCkTF1c1L+WuBwpXoxIvIMsBZ4zXXMWmBT5efngT8SEVFVFZF1wJu4tiQ2ZrJ7aOggT+05EtoxOVUssX/jTXWPh92lO4sewX8/lKHhfN3EutC4LHy+UOSpPUf4rQ9eyNu/bt8QV5hmNvZyeiFgW/kmqZsBJQe4azAcBa4LOkZVx0TkFHCRiBSB/xu4EbDhLjMlDA3nGwYTCJ8wDrqguyvswvmLqJOl5TexrsCsdAqQ0Il0pTwB/tj6ZZEXYXaTtxdiASQ53ZxD8eujev9fCjpmM/CYqp5u+CEi94rIXhHZe/z4pN292EwDQdV+vYImhoMm8dN9Un2N33qSB7btDwxEhdFSdS4hjDrtb3IRYqekRGwupI26GVCOAu4ls5cCx4KOEZF+YA5wgnJP5g9E5G3Ku0r+MxG5z+9DVPUJVV2hqivmzZuX7DcwJkFRJpbDquWuW55j6x1LaybXs5k0W+9cWtMz8euJBJlT+bwoe6kfKxRjbavbqmwmHTuRIGj1vElGN4e8XgUuF5FFQB64C/i055jtwD3Aj4E7gF2qqsD/7BwgIpuA06r6R51otDFJcteL6mtQ40qA31l6ccP3KoyWAoshxs2GOnNujIeGDrL79ca9++xAmoEZ/YnMo2TSKW6/Jsfu148Hvt/smf0Mrr4i1mJNW0fSXl0LKJU5kfuAnUAK+IaqjojIw8BeVd0OfB34logcptwzuatb7TUm6WKB3pXrjQomKvBUZR+RR9ZdFfpe+UKR+7ftZ9P2EX5n6cXsfv14pKDlVRrXSPM6AKfPjnHlxe9rOaCkRLj9mlz1Oy7asMP3892JBlHmboTyeVm5ZZdNvreJaK8PeiZoxYoVunfv3m43w0xCfmVLMulUS+PxK7fsauriK8Bj65fVfG6z75W0sErC6VT9vvNB3Oc26LvlspmaoThvwF+1eF7gmFrLAAAXfUlEQVS1h+PdeMzvb2fVhYOJyD5VXdHoOFspb0wE7SgW2GxdKGcC3C1uMHEW9TW3Dj9YWO9n/ceiVxl2n9soq9b9gsEj665icPUVpETqejjev51VF06GBRRjImhHscBWxvO9ASRo1XeQCVXe3rKGx1zViP3qYSVFgO8eeDfWa9wFLm+/Jlf9js6QmLfopTcYPDR0kAdfPBgY5Nx/O6sunAwLKMZE0I5igX533uk+iVy/a6GrJHvcXRDd61Kc1eAz+9u32l2JvwDRaaOz6NL5juOqvLAvX+09BAWDp195J3Sy3v23s+rCybDy9cZE4JdN5J7kdcbr446/l1eil98zm0lX9zx3hm8y6T5GG6xUf/DFgww0OM7NPVwUZWvhbnC3Maz3sG55LvCiHxZkvUNmczJp34BnWWHxWEAxJgL3Og7vJG++UOTJSvaV87t7K1k/fpP8741NVF/jft3CDTtC2xZ2Fz6Q7kOhWj7Fva1vM/ujeHknu8PMHUhTGC01PD5XmVDfuvMQD2zbH3i8E0iCKgQEJQh4FzcODec5c26s7jj3glATjQ15GRORMzyUy2YaXhQbjb/HGbNvtEo9yOwZKRSpqcXl3ta32f1R3O36zPULIhWGFMpl8MPO2+Prl/H2ljUMrr6CF/blq3MiQZzeg1+FgHRKuPu6+b6T+d595rfuPOSbfXbBrH7L8orJAooxMUUdV88XitVxfu9WtGEbVnkNrr6iqWysM+fGfYPW/dv2R04zntnfV/fZ7t9XXHZh5NIsYXKeYo1RAl2+UOSDD36P5/Yeqf8ArW1bWAn6oL9nocdrkvUiW4diTAPelNQz741FnmB2Vny/sC9fN//i939eSoQJ1bp5mEbDXs2IMlzVB4TNzAjwmesXsOKyC/nSswdiJwdA/ZqQoIWMcXnXqQSJus5lOrN1KMZE4O05eNcd+KWknjk3Rjpsi0OXoGwjxX8NyLiq7zqIZoe9wkS5aDea5lfgyT1HGHy+uWAC5V6QW9hGYHHSo6P2JG13xuRYQDHTVpTFbH7DL6Vx5YJZ/TVDKZ+9fkHg5wRdaLXyWsF/HYl7TmXV4t4ubBp1BbzD/W0LxVLNeQ+7wMcJWlEztGx3xuRYlpeZthqlo0L4+Prwl2s3uQorZOjHPaSyKGBI61hlHuaFfdFXbMfJvOoWv5Xrm7aPVIcWswNpZvb3capY4pJshoUXZfjSswciv3/cHobti5IM66GYaSvKYrY4Cxr97qyDBmiE2n1Nwj4nbjZWrweTIIViqdpbPDla4sy5MeZk0uQLRV5+40Ro78Q9bJbNpK2H0SUWUMy0FSVY+K5mTwln3hurm3fxGzoJugQqtWtUwoZ54i46bCYjrNU5mqir++MojWvD5AcBUn1SXcMD1PxsOssCipm2okzGeoPE3IE045ULnTPvMvjcgZqg4pQyeXnDDYGTyN7Hw8bx49bpUoicNOAYXH0Fb29ZEzoXFKa/T3A+MiXCQBvrgrldks0wPlEbtq0GV/dY2rCZ1uKWLF+2+fu+d81O2RTve92/bX/ge332+gV1+5r4ta2ZsiiPr1/Gpu0j1bbOHUhz5cXv4+U3ToS+LpfNcPxvznIu5iS7V5/ARJsvLU6Ktd/HCPDWljXtbcA0EjVt2CblzbQWdzI2aAjGyVTybnAlQuA+60/uOcJbx08zcuxvai78G28p1/NqtizK7BnlXtfsmf2cKpaYkylvk/ujN040rPmVVE2vKMHEWX/SbNC8+7r5gYkQVoOrO2zIy5iE+F38Gw0AvPzGiZogdXK0xODzB9j80kjTZVFUtSYdulAsVcueRC0g2QlOCfpVi+fFmvdJiVR7d7aGpLdYD8WYGOYOpBtuNduq0ri29Bm9FDTCfPfAu6y47EK2vfpOw8y0lEhdDS5nSLBYGq8WgszZTotdZT0UY2LYeMsS30KEcwfSXWrR5FUoltj80kjDRZF+BR3di1KhvHjU6ZlYMOmergYUEblZRA6JyGER2eDz/EwR2VZ5/hURWVh5/EYR2SciByv/toI7piPWLc+x9Y6lNdlYW+9YysZblkSquhtVNpNuSyquYyBdX/SxG8J6YmGr1m2Hxd7UtSEvEUkBXwNuBI4Cr4rIdlV9zXXYF4CTqvohEbkL+AqwHvgVcIuqHhORjwA7AbstMXXiZnFFETaR786sCtMn8Hd+80L++1snKXlmsFOV/Nu45UyiyqRT/Mvbytllv/edg5w513wJ+yjCEhPChGVp2Q6LvambPZRrgcOq+qaqngOeAdZ6jlkLfLPy8/PAJ0REVHVYVY9VHh8BZonIzI602kwaUWp1eY8PKhTZqIgklAPN/o038fj6ZQ3bNrM/xZ0rFrD1zqVkM+eHy2bPSNFH/O1yo/C74x+NEUzirodxNBNMGu1v344tmU3rujkpnwPecf1+FLgu6BhVHRORU8BFlHsojtuBYVV9r41tNZNQlFpdDu/uhU7w2fuLE7yw72jNJlWNdmRctzzXMBXWacfLG26oeY+o+5Q0w3vHv3XnoVhlWt6f6WfN1RfXleJvh1kNhg/9tmS27K7u62ZA8bvd8f73HXqMiCyhPAx2k89xzjH3AvcCLFjQ3CpgMznFGRYJCj7urX29z3kDk3t4bU5lDiRs2ModOJLa2z1oQeHcgXTd8F+jz/KuWTk5WuKFfXluvybH06+803S5+igabW7l3owryeFM05puBpSjwHzX75cCxwKOOSoi/cAc4ASAiFwKfAf4nKq+EfQhqvoE8ASUV8on1nrT87IBKb5Zn4ysZsbej3kCgvuOuVAske6ThmnGztBZq3u7QzloqNYPl/UJrLn64roeWJjPXr+A3a8fZ9RzXLE0zu7Xj3P3dfN5as+RmjvAdEqYPaM/keG6KENXViG493QzoLwKXC4ii4A8cBfwac8x24F7gB8DdwC7VFVFJAvsAB5U1Zc72GbTw7x34O8FXKC9N9ZDw3n6KusY4nBf9Hz3TZlQ/ro4FvoeYaVZ4goKXKk+YcdP340csJw6XEFBJ18o8sK+fE0wEWD9x+bzyLqrWt5xMZ0SG7qapLoWUCpzIvdRztBKAd9Q1REReRjYq6rbga8D3xKRw5R7JndVXn4f8CHgn4vIP688dpOq/rKz38J0g1/mFhD5DvyU6w7a6VnEDSbe8vNBPZxWh4WS2Nsk7kLJ0dJE4FAflCfn/XagfHLPEXa/fjywZxiFU3omaCjRhrZ6mxWHNJOKd2gJypOxM/v7Ig+1uDe2amUS3L0qu12T6dlMGpHynMIl2QyrFs/juwfebUsWWBSZdKphTyfdJyD1ac+ZdB+z0infYOOcy0Y3Ck4bbL+TzopaHNICiplUWr1wO3f8qYhDXH3ArJCCigJ85voFrLjswkTmQfy4L6APDR2sm7vopMfXL4uUPJDNpJk9s7+uVxE2HOYNVmG9M/dNgWk/qzZsJpWowxpxJ8+dC1u+UKy5QEUdipI+4V/ednVgL8QZ6vnugXdrakoluQ1vsTTOA8/u55+9+NOu1ulKiVT/Jo2CZ6FYYtOtS+r+hkHZZUHDaEFsAWNvslpepuviLEAMyv6ZPSNVl2OeSafYdOsSXt5wQ+juiWHGJ5QvPrufRRt2hN6VO0NQ46qk+4S+mBtcNaLa/aKP46qs3LKLB7btZ1a6r2ZBph+/v2FQdeBWEiJM77CAYrouTl2moC15z41N1GUdOeXRobV9PiY0Xm+jNKF1uwhOBQI1e76/NzbBZ69fEFjDzPs39FYHhvMr9+NsQWwLGHuXBRTTdXEWIPptlTt7Rn9dPSwFdr9+HChfyHqhEOJk5jeE56xJefS24F0nnb+hX3XgdJ8wem6MB7btZ/TcWKRti4OKRZreYHMopuuCxtWDhjW8C9oWbdjhe1y+UKzeFYf1FzLpFLdfkwtNlZ3OciGr6o8ViqGlZpy/YdA6HSfj6+RoiXRKyGbSFIqlugBmmV2Tg/VQTNcFDWOdeW8stBijI2w83X1X7Me5431k3VUN5wQccwfS1SGahKdKekomneLx9cuqc1B+nHPfaOfEKJPopXFl9sx+3t6yhsfWL6vphVowmRysh2KakuRiM29dpuxAmtNnx6oT3Y2KMfoVCnQUS+OB5dO9qaebbl3C4HMH6obP3NIpaXnP98niowvmVM93UDHGVYvnsXLLrurfbWZ/H6eKpbr/JqLUDoPzgcfKqkxOFlBMbEGVecH/gh+F+wKycsuuusVvQVWC3Z8ZVMZEtbzYzh0ovBdDZ9HgBbP6Q1d5z57RX00hnsrBBOBHb5xgaDhfPb+z0n3V75xJ9yFozTDhydESmXSKx9Yvq/s7hQV9N8vemtxsyMvE1u7d8prZPGnd8lxoptAFs/qrQyjZTJo+Ka8fcacqP7nnSMOSIYViiaHh/LRYB6GUg/Tyh7/P4HMHas5NsTThm8Yc9N+BN5nCb0dKy96a/KyHYqpaXVyY1EU27iS9Y3D1FYG9lJOjJbSS/nuqWGpp0eGDLx5kTmXyeDqIW5cr6L8D7zCW1eiaeiygGCDeMFazF/yoWtk8KWyFuhMAWl0hUiyNT/nhrlZE/e/A5kmmHgsoBoi3u2GUC7737nPV4nnsfv145LtRd/aUd5Gi+zM2vzTSdGXbqeDtLWsYGs5H3su+3WzYanqzgGKA+IsLIXi3PL/ejnvy1r29rjfIAAw+f6CmUq0C2/77O6y47MKaz/AeNx0t3LCD2TNSnImxN3y7+JWeN9OLVRs2QHAV32aqujZbETidEi6Y2SjLqjcunua8bCbtWwjSTB1Rqw1blpcBGi9Mi6PZyfkoG0FZMOmeXDbD454Fh4+vX8b+jTdZMDGA9VCmtbB5juxAmvdK49XU0Gwmze8svTjSPMiyzd/vifF8k6zHfdaXmOnBNtjy0Y6A4r4oZwfSqOK7UjjOa7MDac6WximGlCt3xqv3/uIET71yxHcluDFxZNJ9gf/NzR1IM/zlmzrcItMrbIOtNvC7o39hX746+ewerglLu/XLynG/NkrW0snRUuCaC2PiSvcJj952dfkGxbMjZCadqpabMSZMV+dQRORmETkkIodFZIPP8zNFZFvl+VdEZKHruQcrjx8SkdXtbqvfJlBP7TkSuh7Bb9Ww8z42JGS6KZtJ18yFbL1zKeuW53hk3VVWmNE0rWs9FBFJAV8DbgSOAq+KyHZVfc112BeAk6r6IRG5C/gKsF5ErgTuApYAlwB/LiIfVtW2zdj6rdOIMsrknaD2ex9jOsnZyTIoSNiCQ9OsbvZQrgUOq+qbqnoOeAZY6zlmLfDNys/PA58QEak8/oyqvqeqbwGHK+/XNs1mLnlXDU+HGlAmnmYr4Dvl5d/esqYm+2ruQJpsJl3tYXz2+gXW4zAd0c05lBzwjuv3o8B1Qceo6piInAIuqjy+x/Na3/9DRORe4F6ABQsWNN3YoHIjYaU+/NJuo5bxNpNXLpthYEYfP//lGd/n/JI1glb9Z9J9zEqnKIyWQpM+rFdhekE3A4rfjZn32hx0TJTXlh9UfQJ4AspZXnEa6BZUbuT2a3I1qbaNsryilvE27ZcS4frfnMvbvy6SLxRJiTCuytzK37FQLNEn5T3lHe1aDW4BwUwF3QwoR4H5rt8vBY4FHHNURPqBOcCJiK9NVKNyI82+T3YgzanREu5kzb/1vhn86nSJcU8u8OwZKSZUq6mdzsUNqLu7dS6E3guiUL7rHS1NVC+gOVfZE7/vF1YV1irGGmMcXVuHUgkQfwV8AsgDrwKfVtUR1zH/BLhKVX+3Mil/m6p+SkSWAN+mPG9yCfBD4PJGk/K2sNEYY+Lr+XUolTmR+4CdQAr4hqqOiMjDwF5V3Q58HfiWiBym3DO5q/LaERF5FngNGAP+STszvIwxxjRmK+WNMcaEsuKQxhhjOsoCijHGmERYQDHGGJMICyjGGGMSYQHFGGNMIiygGGOMSYQFFGOMMYmwgGKMMSYRFlCMMcYkwgKKMcaYRFhAMcYYkwgLKMYYYxJhAcUYY0wiLKAYY4xJhAUUY4wxibCAYowxJhEWUIwxxiTCAooxxphEdCWgiMiFIvIDEfl55d9zA467p3LMz0XknspjAyKyQ0ReF5EREdnS2dYbY4zx060eygbgh6p6OfDDyu81RORCYCNwHXAtsNEVeP6Vqi4GlgMrReS3O9NsY4wxQboVUNYC36z8/E1gnc8xq4EfqOoJVT0J/AC4WVVHVXU3gKqeA34CXNqBNhtjjAnRrYDyt1T1XYDKv3/D55gc8I7r96OVx6pEJAvcQrmXY4wxpov62/XGIvLnwP/k89TvRX0Ln8fU9f79wNPAH6rqmyHtuBe4t/LraRE5FPHzu+EDwK+63YgeZOfFn50Xf3ZegjV7bi6LclDbAoqq/q9Bz4nI/xCRi1X1XRG5GPilz2FHgb/n+v1S4D+7fn8C+LmqPt6gHU9Uju15IrJXVVd0ux29xs6LPzsv/uy8BGv3uenWkNd24J7Kz/cAf+pzzE7gJhGZW5mMv6nyGCLyCDAHuL8DbTXGGBNBtwLKFuBGEfk5cGPld0RkhYj8MYCqngB+H3i18s/DqnpCRC6lPGx2JfATEdkvIv+wG1/CGGPMeW0b8gqjqr8GPuHz+F7gH7p+/wbwDc8xR/GfX5kKJsXQXBfYefFn58WfnZdgbT03oqqNjzLGGGMasNIrxhhjEmEBpcNE5GYROSQih0WkrkKA67g7RERFZNpkq0Q5NyLyKRF5rVJ259udbmM3NDovIrJARHaLyLCI/FREPtmNdnaaiHxDRH4pIn8Z8LyIyB9WzttPReSjnW5jN0Q4L5+pnI+fisiPRGRpYh+uqvZPh/4BUsAbwG8CM4ADwJU+x70P+AtgD7Ci2+3ulXMDXA4MA3Mrv/9Gt9vdI+flCeB/r/x8JfB2t9vdoXPzceCjwF8GPP9J4M8oz7leD7zS7Tb3yHn5Ldf/Q7+d5HmxHkpnXQscVtU3tVw25hnKZWi8fh/4A+BsJxvXZVHOzT8CvqblUjyoqt/6pakmynlR4P2Vn+cAxzrYvq5R1b8AToQcshb4Ey3bA2Qr696mtEbnRVV/5Pw/RPmmNbHSVRZQOitKOZnlwHxV/W4nG9YDGp4b4MPAh0XkZRHZIyI3d6x13RPlvGwCPisiR4HvAf9HZ5rW86Kcu+nuC5R7cYnoStrwNNaonEwf8Bjw+U41qIeEnpuKfsrDXn+P8l3VfxWRj6hqoc1t66Yo5+Vu4P9T1a+KyN8BvlU5LxPtb15Pi3Lupi0RWUU5oPzdpN7TeiiddRSY7/r9UmqHJ94HfAT4zyLyNuVx3+3TZGK+0blxjvlTVS2p6lvAIcoBZiqLcl6+ADwLoKo/BmZRrtk03UU5d9OSiFwN/DGwVsvrAhNhAaWzXgUuF5FFIjIDuItyGRoAVPWUqn5AVReq6kLK45u3annB51QXem4qhoBVACLyAcpDYIGFQaeIKOflCJWFwiLytykHlOMdbWVv2g58rpLtdT1wSitVzqczEVkAvAj8fVX9qyTf24a8OkhVx0TkPso1yVLAN1R1REQeBvaqqvdCMW1EPDdOfbfXgHFgMMm7q14U8bx8Cfh/ROQBykM6n9dKCs9UJiJPUx7+/EBl/mgjkAZQ1f9AeT7pk8BhYBT4B91paWdFOC9fBi4C/p2IAIxpQgUjbaW8McaYRNiQlzHGmERYQDHGGJMICyjGGGMSYQHFGGNMIiygGGOMSYQFFGM6RERO+zz2uyLyucrPiys7kA6LyDUi8o8730pjmmdpw8Z0iIicVtULQp7fAGRUdaOILAS+q6of6VT7jGmVLWw0potEZBNwGngNuB8YF5GPA/8D+KCI7Ad+oKqD3WulMdFYQDGmB6jq90TkPwCnVfVfVXooH1HVZd1tmTHR2RyKMcaYRFhAMcYYkwgLKMb0pr+hvJ2BMZOGBRRjOmdARI66/vli0IGVKsovi8hfisjWDrbRmKZZ2rAxxphEWA/FGGNMIiygGGOMSYQFFGOMMYmwgGKMMSYRFlCMMcYkwgKKMcaYRFhAMcYYkwgLKMYYYxLx/wNHMoRkeXz0igAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../python')\n",
    "import time\n",
    "from plot_info import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import keras\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "qmc_points = np.loadtxt('../sobol_6_8000.txt')\n",
    "qmc_points = qmc_points[1:].reshape((8000,6))\n",
    "\n",
    "all_points = qmc_points.copy()\n",
    "forces = np.array(np.loadtxt('../force_6_params.dat'))\n",
    "\n",
    "plt.scatter(forces[:,1], forces[:,2])\n",
    "plt.xlabel(\"Lift\")\n",
    "plt.ylabel(\"Drag\")\n",
    "plt.show()\n",
    "\n",
    "N = min(qmc_points.shape[0], forces.shape[0])\n",
    "qmc_points = qmc_points[:N,:]\n",
    "forces  = forces[:N,:]\n",
    "\n",
    "permuted_indices = range(N)#np.random.permutation(N)\n",
    "qmc_points=qmc_points[permuted_indices,:]\n",
    "forces = forces[permuted_indices,:]\n",
    "input_size=6\n",
    "force_component = 1\n",
    "train_size=128\n",
    "validation_size=200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_network(parameters, data, *,train_size, validation_size, batch_size, title):\n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(input_size,)),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  loss='mean_squared_error')\n",
    "    x_train = parameters[:train_size,:]\n",
    "    y_train=data[:train_size]\n",
    "    \n",
    "    \n",
    "    x_val = parameters[train_size:validation_size+train_size,:]\n",
    "    y_val=data[train_size:train_size+validation_size]\n",
    "    epochs=500000\n",
    "    \n",
    "    training_start_time=time.time()\n",
    "    hist = model.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,shuffle=True, \n",
    "                     validation_data=(x_val, y_val),verbose=0)\n",
    "    training_end_time=time.time()\n",
    "    print(\"Training took {} seconds\".format (training_end_time-training_start_time))\n",
    "    \n",
    "    epochs_r=range(1, epochs)\n",
    "    plt.loglog(hist.history['loss'])\n",
    "    plt.title('Training loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('training_loss')\n",
    "    \n",
    "    plt.loglog(hist.history['val_loss'])\n",
    "    plt.title('Validation loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('validation_loss')\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.loglog(hist.history['loss'], label='Training loss')\n",
    "    plt.loglog(hist.history['val_loss'],label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training loss and validation loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('training_validation_loss')\n",
    "    \n",
    "    \n",
    "    plt.title('Validation loss (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('validation_loss')\n",
    "    \n",
    "    \n",
    "    x_test =  parameters[validation_size+train_size:,:]\n",
    "    y_test = data[train_size+validation_size:]\n",
    "    y_predict = model.predict(x_test)\n",
    "    \n",
    "    plt.title('Scatter comparision (%d samples, batch size: %d)\\n%s' %(train_size, batch_size, title))\n",
    "    plt.scatter(y_test, y_predict)\n",
    "    plt.xlabel(\"Actual data\")\n",
    "    plt.ylabel(\"Predicted data\")\n",
    "    showAndSave(\"scatter_comparison\")\n",
    "    print(model.summary())\n",
    "    \n",
    "   \n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.LinearRegression()\n",
    "    coeffs = reg.fit(parameters[:train_size,:], y_train)\n",
    "    \n",
    "    evaluated_lsq = coeffs.predict(parameters)\n",
    "    plt.scatter(data, evaluated_lsq)\n",
    "    plt.title('Linear Least squares (%d samples)' % (train_size))\n",
    "    plt.xlabel(\"Actual data\")\n",
    "    plt.ylabel(\"Interpolated data\")\n",
    "    showAndSave(\"scatter_lsq_comparision\")\n",
    "    \n",
    "    \n",
    "    def myvar(x):\n",
    "        mean = np.sum(x)/x.shape[0]\n",
    "        var = np.sum((mean-x)**2)/x.shape[0]\n",
    "        return var\n",
    "        \n",
    "    def mymean (x): \n",
    "        return np.sum(x)/x.shape[0]\n",
    "    \n",
    "    variance_top = myvar(data)\n",
    "    print(\"variance single level = %f\" % variance_top)\n",
    "    predicted = model.predict(parameters)\n",
    "    predicted = predicted.reshape(parameters.shape[0])\n",
    "    variance_diff_ml = myvar(data - predicted)\n",
    "    \n",
    "    \n",
    "    print(\"variance diff ml = %f \" % variance_diff_ml)\n",
    "    print(\"speedup = %f\" % (variance_top/variance_diff_ml/2.))\n",
    "    print((data - evaluated_lsq).shape)\n",
    "    variance_diff_interpolate =myvar(data - evaluated_lsq)\n",
    "    print(\"variance_diff_interpolate = %f\" % variance_diff_interpolate)\n",
    "    \n",
    "    mean_qmc = np.mean(data)\n",
    "    print(\"mean_qmc = %f\" % mean_qmc)\n",
    "    mean_ml = np.mean(model.predict(parameters))\n",
    "    print(\"mean_ml = %f\" % mean_ml)\n",
    "    mean_few_qmc = np.mean(parameters[:train_size,:])\n",
    "    \n",
    "    print(\"mean_few_qmc = %f\" % mean_few_qmc)\n",
    "    predicted_all = model.predict(all_points)\n",
    "    predicted_all = predicted_all.reshape(all_points.shape[0])\n",
    "    print(predicted_all.shape)\n",
    "    mean_mlmlmc = mymean(predicted[:train_size]-data[:train_size]) + mymean(predicted_all)\n",
    "    \n",
    "    print(\"mean_mlmlmc = %f\" % mean_mlmlmc)\n",
    "    var_qmc = np.var(data)\n",
    "    print(\"var_qmc = %f\" % var_qmc)\n",
    "    var_ml = np.var(model.predict(parameters))\n",
    "    print(\"var_ml = %f\" % var_ml)\n",
    "    var_few_qmc = np.var(parameters[:train_size,:])\n",
    "    \n",
    "    print(\"var_few_qmc = %f\" % var_few_qmc)\n",
    "    print(parameters.shape)\n",
    "    \n",
    "    \n",
    "   \n",
    "    plt.hist(data,bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.title(\"Comparison QMC and DLMC\\n%s\\nepochs=%d,batch_size=%d\"% (title, epochs,batch_size))\n",
    "    plt.hist(model.predict(parameters),bins=40,density=True,label='DLMC (%d samples)' % train_size,alpha=0.5)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_ml_%s' % title)\n",
    "    \n",
    "    \n",
    "    plt.title(\"Comparison QMC with %d and QMC with %d samples\\n%s\" %(parameters.shape[0], train_size, title))\n",
    "    plt.hist(data,bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.hist(data[:train_size],bins=40,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_qmc_%s' % title)\n",
    "    \n",
    "    plt.title(\"Comparison QMC with least squares\\n%s\" % title)\n",
    "    plt.hist(data,bins=40,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "    plt.hist(evaluated_lsq,bins=40,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_lsq_%s' % title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.hist(data,bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.title(\"(coarse hist) Comparison QMC and DLMC\\n%s\\nepochs=%d,batch_size=%d\"% (title, epochs,batch_size))\n",
    "    plt.hist(model.predict(parameters),bins=20,density=True,label='DLMC(%d samples)' % train_size,alpha=0.5)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_ml_coarse_%s' % title)\n",
    "    \n",
    "    \n",
    "    plt.title(\"(coarse hist) Comparison QMC with %d and QMC with %d samples\\n%s\" %(parameters.shape[0], train_size, title))\n",
    "    plt.hist(data,bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "    plt.hist(data[:train_size],bins=20,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_qmc_coarse_%s' % title)\n",
    "    \n",
    "    plt.title(\"(coarse hist) Comparison QMC with least squares\\n%s\" % title)\n",
    "    plt.hist(data,bins=20,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "    plt.hist(evaluated_lsq,bins=20,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "    plt.legend()\n",
    "    showAndSave('hist_qmc_lsq_coarse_%s' % title)\n",
    "    \n",
    "    samples = range(0,data.shape[0])\n",
    "    stats = {}\n",
    "    for stat in ['mean', 'var']:\n",
    "        stats[stat]={}\n",
    "        stats[stat]['sources']={}\n",
    "        if stat == 'mean':\n",
    "            stats[stat]['compute']=lambda x: sum(x)/x.shape[0]\n",
    "        else:\n",
    "            stats[stat]['compute']=lambda x: sum(x**2)/x.shape[0]-(sum(x)/x.shape[0])**2\n",
    "    \n",
    "     \n",
    "        stats[stat]['sources']['QMC']={}\n",
    "        stats[stat]['sources']['DLMC'] = {}\n",
    "        stats[stat]['sources']['Least squares'] = {}\n",
    "        stats[stat]['sources']['DLbMC'] = {}\n",
    "    \n",
    "        stats[stat]['sources']['QMC']['data']=array([stats[stat]['compute'](data[:k]) for k in samples])\n",
    "        stats[stat]['sources']['DLMC']['data'] = array([stats[stat]['compute'](array(model.predict(parameters[:k,:]))) for k in samples])\n",
    "        stats[stat]['sources']['Least squares']['data'] = array([stats[stat]['compute'](evaluated_lsq[:k]) for k in samples])\n",
    "        \n",
    "        stats[stat]['sources']['DLbMC']['data'] = [0]\n",
    "        \n",
    "        for k in samples[1:]:\n",
    "            if stat == 'mean':\n",
    "                mean = sum(model.predict(parameters[:train_size,:])-data[:train_size])/train_size +\\\n",
    "                sum(model.predict(parameters[:k,:]))/k\n",
    "                \n",
    "\n",
    "                stats[stat]['sources']['DLbMC']['data'].append(mean)\n",
    "            elif stat=='var':\n",
    "                mean = sum(model.predict(parameters[:train_size,:])-data[:train_size])/train_size +\\\n",
    "                sum(model.predict(parameters[:k,:]))/k\n",
    "                \n",
    "                m2 = sum((model.predict(parameters[:train_size,:]))**2-(data[:train_size])**2)/train_size +\\\n",
    "                sum(model.predict(parameters[:k,:])**2)/k\n",
    "                \n",
    "\n",
    "                stats[stat]['sources']['DLbMC']['data'].append(m2-mean**2)\n",
    "                \n",
    "        stats[stat]['sources']['DLbMC']['data']=array(stats[stat]['sources']['DLbMC']['data'])\n",
    "        \n",
    "        sources = stats[stat]['sources'].keys()\n",
    "        for source in sources:\n",
    "            \n",
    "            stats[stat]['sources'][source]['representative'] = stats[stat]['sources'][source]['data'][-1]\n",
    "            \n",
    "        \n",
    "       \n",
    "    \n",
    "        for source in stats[stat]['sources'].keys():\n",
    "            if 'DLbMC' not in source:\n",
    "                plt.plot(samples, stats[stat]['sources'][source]['data'], label=source)\n",
    "        plt.xlabel('Number of samples ($J_N$)')\n",
    "        plt.ylabel('%s' % stat)\n",
    "        plt.title('%s as a function of number of samples used for evaluation\\n%s' % (stat, title))\n",
    "        plt.legend()\n",
    "        showAndSave('function_of_samples_airfoil_%s_%s'  % (stat, title))\n",
    "        stats[stat]['sources']['QMC_%d' % train_size] = {}\n",
    "        stats[stat]['sources']['QMC_%d' % train_size]['representative'] = stats[stat]['sources']['QMC']['data'][train_size]\n",
    "    sources = [source for source in stats['mean']['sources'].keys()]\n",
    "    for source in sources:\n",
    "        if source != sources[-1]:\n",
    "            sys.stdout.write('\\\\multicolumn{2}{c|}{\\\\textbf{%s}} &&' % source)\n",
    "        else:\n",
    "            sys.stdout.write('\\\\multicolumn{2}{c|}{\\\\textbf{%s}} \\\\\\\\ \\n' % source)\n",
    "    for source in sources:\n",
    "        for stat in ['mean', 'var']:\n",
    "            if not (stat == 'var' and source ==  sources[-1]):\n",
    "                sys.stdout.write(\"%s && \" % stat)\n",
    "            else:\n",
    "                sys.stdout.write(\"%s \\\\\\\\ \" % stat)\n",
    "           \n",
    "    for source in sources:\n",
    "        for stat in ['mean', 'var']:\n",
    "            if not (stat == 'var' and source ==  sources[-1]):\n",
    "                sys.stdout.write(\"%.5f &&\" % stats[stat]['sources'][source]['representative'])\n",
    "            else:\n",
    "                sys.stdout.write(\"%.5f \\\\\\\\ \\n\" % stats[stat]['sources'][source]['representative'])\n",
    "            \n",
    "        \n",
    "    #for stat in ['mean', 'var']:\n",
    "    #    stats[stat]={}\n",
    "    #    stats[stat]['sources']={}\n",
    "    #    if stat == 'mean':\n",
    "    #        stats[stat]['compute']=lambda x: sum(x)/x.shape[0]\n",
    "    #    else:\n",
    "    #        stats[stat]['compute']=lambda x: sum(x**2)/x.shape[0]-(sum(x)/x.shape[0])**2\n",
    "    #\n",
    "    # \n",
    "    #    stats[stat]['sources']['QMC']={}\n",
    "    #    stats[stat]['sources']['DLMC'] = {}\n",
    "    #    stats[stat]['sources']['Least squares'] = {}\n",
    "    #\n",
    "    #    stats[stat]['sources']['QMC']['data']=array([stats[stat]['compute'](data[:k]) for k in samples])\n",
    "    #    stats[stat]['sources']['DLMC']['data'] = array([stats[stat]['compute'](array(model.predict(parameters[:k,:]))) for k in samples])\n",
    "    #    stats[stat]['sources']['Least squares']['data'] = array([stats[stat]['compute'](evaluated_lsq[:k]) for k in samples])\n",
    "    #    stats[stat]['sources']['DLbMC']['data'] = []\n",
    "    #    \n",
    "    #    \n",
    "    #   \n",
    "    #\n",
    "    #    for source in stats[stat]['sources'].keys():\n",
    "    #        plt.plot(samples, stats[stat]['sources'][source]['data'], label=source)\n",
    "    #        plt.xlabel('Number of samples ($J_N$)')\n",
    "    #        plt.ylabel('%s' % stat)\n",
    "    #        plt.title('%s as a function of number of samples used for evaluation\\n%s\\n%s' % (stat, title,source))\n",
    "    #        plt.legend()\n",
    "    #        showAndSave('function_of_samples_airfoil_%s_%s_%s' % (source, stat, title))\n",
    "    #\n",
    "    #\n",
    "    #for stat in ['mean','var']:\n",
    "        \n",
    "        \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "batch_sizes=[16, 32, train_size]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for (n, f) in enumerate(force_names):\n",
    "        showAndSave.prefix='airfoil_%s_ts_%d_bs_%d' %(f,batch_size, train_size)\n",
    "        network= get_network(qmc_points, forces[:,n+1], train_size=train_size, validation_size=validation_size,\n",
    "                        batch_size=batch_size, title=f)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One network to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_dual(parameters, data, *,train_size, validation_size, batch_size, title, names):\n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape=(input_size,)),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(12),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(10),\n",
    "        Activation('relu'),\n",
    "        Dense(data.shape[1])\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  loss='mean_squared_error')\n",
    "    x_train = parameters[:train_size,:]\n",
    "    y_train=data[:train_size,:]\n",
    "    \n",
    "    \n",
    "    x_val = parameters[train_size:validation_size+train_size,:]\n",
    "    y_val=data[train_size:train_size+validation_size,:]\n",
    "    epochs=500000\n",
    "    \n",
    "    training_start_time=time.time()\n",
    "    hist = model.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,shuffle=True, \n",
    "                     validation_data=(x_val, y_val),verbose=0)\n",
    "    training_end_time=time.time()\n",
    "    print(\"Training took {} seconds\".format (training_end_time-training_start_time))\n",
    "    \n",
    "    epochs_r=range(1, epochs)\n",
    "    plt.loglog(hist.history['loss'])\n",
    "    plt.title('Training loss (%d samples, batch size: %d, output_size: %d)\\n%s' %(train_size, batch_size, data.shape[1], title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('training_loss_dual')\n",
    "    \n",
    "    plt.loglog(hist.history['val_loss'])\n",
    "    plt.title('Validation loss (%d samples, batch size: %d, output_size: %d)\\n%s' %(train_size, batch_size, data.shape[1], title))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    showAndSave('validation_loss_dual')\n",
    "    \n",
    "    \n",
    "    x_test =  parameters[validation_size+train_size:,:]\n",
    "    y_test = data[train_size+validation_size:,:]\n",
    "    y_predict = model.predict(x_test)\n",
    "    \n",
    "    for c in range(data.shape[1]):\n",
    "        plt.title('Scatter comparision %s (%d samples, batch size: %d)\\n%s' %(names[c], train_size, batch_size, title))\n",
    "        plt.scatter(y_test[:,c], y_predict[:,c])\n",
    "        plt.xlabel(\"Actual data\")\n",
    "        plt.ylabel(\"Predicted data\")\n",
    "        showAndSave(\"scatter_comparison_dual_%s\" % names[c])\n",
    "        print(model.summary())\n",
    "    \n",
    "   \n",
    "    from sklearn import linear_model\n",
    "    \n",
    "      \n",
    "    for c in range(data.shape[1]):\n",
    "        reg = linear_model.LinearRegression()\n",
    "        coeffs = reg.fit(parameters[:train_size,:], y_train[:,c])\n",
    "        evaluated_lsq = coeffs.predict(parameters)\n",
    "        plt.scatter(data[:,c], evaluated_lsq)\n",
    "        plt.title('Linear Least squares %s (%d samples)' % (names[c], train_size))\n",
    "        plt.xlabel(\"Actual data\")\n",
    "        plt.ylabel(\"Interpolated data\")\n",
    "        showAndSave(\"scatter_lsq_comparision_dual_%s\" % names[c])\n",
    "    \n",
    "   \n",
    " \n",
    "        plt.hist(data[:,c],bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.title(\"Comparison QMC and DLMC %s\\n%s\\nepochs=%d, batch_size=%d\"% (names[c], title, epochs,batch_size))\n",
    "        plt.hist(model.predict(parameters)[:,c],bins=40,density=True,label='DLMC(%d samples)' % train_size,alpha=0.5)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_ml_dual_%s' % names[c])\n",
    "        \n",
    "        \n",
    "        plt.title(\"Comparison QMC with %d and QMC with %d samples\\n%s\\n%s\" %(parameters.shape[0], train_size, names[c], title))\n",
    "        plt.hist(data[:,c],bins=40,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.hist(data[:train_size,c],bins=40,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_qmc_dual_%s' % names[c])\n",
    "        \n",
    "        plt.title(\"Comparison QMC with least squares %s\\n%s\" % (names[c], title))\n",
    "        plt.hist(data[:,c],bins=40,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "        plt.hist(evaluated_lsq,bins=40,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_lsq_dual_%s' % names[c])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.hist(data[:,c],bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.title(\"Comparison QMC and DLMC %s\\n%s\\nepochs=%d, batch_size=%d\"% (names[c], title, epochs,batch_size))\n",
    "        plt.hist(model.predict(parameters)[:,c],bins=20,density=True,label='DLMC(%d samples)' % train_size,alpha=0.5)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_ml_dual_%s_coarse' % names[c])\n",
    "        \n",
    "        \n",
    "        plt.title(\"Comparison QMC with %d and QMC with %d samples\\n%s\\n%s\" %(parameters.shape[0], train_size, names[c], title))\n",
    "        plt.hist(data[:,c],bins=20,density=True,label='QMC %d samples' % parameters.shape[0],alpha=0.5)\n",
    "        plt.hist(data[:train_size,c],bins=20,density=True, alpha=0.5,label='QMC %d samples' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_qmc_dual_%s_coarse' % names[c])\n",
    "        \n",
    "        plt.title(\"Comparison QMC with least squares %s\\n%s\" % (names[c], title))\n",
    "        plt.hist(data[:,c],bins=20,density=True,label='QMC %d samples' % train_size,alpha=0.5)\n",
    "        plt.hist(evaluated_lsq,bins=20,density=True,alpha=0.5, label='Least squares (%d points)' % train_size)\n",
    "        plt.legend()\n",
    "        showAndSave('hist_qmc_lsq_dual_%s_coarse' % names[c])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        samples = range(0,data.shape[0])\n",
    "        stats = {}\n",
    "        for stat in ['mean', 'var']:\n",
    "            stats[stat]={}\n",
    "\n",
    "            stats[stat]['sources']={}\n",
    "            if stat == 'mean':\n",
    "                stats[stat]['compute']=lambda x: sum(x)/x.shape[0]\n",
    "            else:\n",
    "                stats[stat]['compute']=lambda x: sum(x**2)/x.shape[0]-(sum(x)/x.shape[0])**2\n",
    "            \n",
    "            stats[stat]['sources']['QMC']={}\n",
    "            stats[stat]['sources']['ML'] = {}\n",
    "            stats[stat]['sources']['Least squares'] = {}\n",
    "    \n",
    "            print(parameters.shape)\n",
    "            print(array(model.predict(parameters[:10,:])).shape)\n",
    "            print(array(model.predict(parameters[:1,:])).shape)\n",
    "            print(array(model.predict(parameters[:0,:])).shape)\n",
    "            stats[stat]['sources']['QMC']['data']=array([stats[stat]['compute'](data[:k,c]) for k in samples])\n",
    "            \n",
    "            stats[stat]['sources']['ML']['data'] = [0]\n",
    "            for k in samples[1:]:\n",
    "                stats[stat]['sources']['ML']['data'].append(stats[stat]['compute'](array(model.predict(parameters[:k,:]))[:,c]))\n",
    "                \n",
    "          \n",
    "            stats[stat]['sources']['Least squares']['data'] = array([stats[stat]['compute'](evaluated_lsq[:k]) for k in samples])\n",
    "            \n",
    "            \n",
    "            for source in stats[stat]['sources'].keys():\n",
    "                plt.plot(samples, stats[stat]['sources'][source]['data'], label=source)\n",
    "            plt.xlabel('Number of samples ($J_N$)')\n",
    "            plt.ylabel('%s' % stat)\n",
    "            plt.title('%s as a function of number of samples used for evaluation' % stat)\n",
    "            showAndSave('function_of_samples_airfoil_dual_%s_%s' % (names[c], stat))\n",
    "        \n",
    "    \n",
    "    return network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force_names=['Lift', 'Drag']\n",
    "batch_sizes=[16, 32, train_size]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    showAndSave.prefix='airfoil_ts_%d_bs_%d_dual' %(batch_size, train_size)\n",
    "    network= get_network_dual(qmc_points, forces[:,1:], train_size=train_size, validation_size=validation_size,\n",
    "                        batch_size=batch_size, title=\"One network for both variables\",names=force_names)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
