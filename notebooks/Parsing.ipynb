{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../python')\n",
    "import plot_info\n",
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "import copy\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename='../data/airfoils_qmc_{}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "functionals = ['Drag', 'Lift']\n",
    "\n",
    "data = {}\n",
    "\n",
    "for functional in functionals:\n",
    "    data[functional] = []\n",
    "    \n",
    "    filename = basename.format(functional.lower())\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        json_content = json.load(f)\n",
    "        \n",
    "        data[functional] = copy.deepcopy(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_dict_path(dictionary, path):\n",
    "    split = path.split('.')\n",
    "    for s in split:\n",
    "        dictionary = dictionary[s]\n",
    "    return dictionary\n",
    "\n",
    "# As a function of training size\n",
    "def plot_as_training_size(functional, data, title=\"all configurations\"):\n",
    "    train_sizes = []\n",
    "    \n",
    "    for configuration in data['configurations']:\n",
    "        train_size = int(configuration['settings']['train_size'])\n",
    "        if train_size not in train_sizes:\n",
    "            train_sizes.append(train_size)\n",
    "    print(train_sizes) \n",
    "    train_sizes = sorted(train_sizes)\n",
    "    \n",
    "    data_source_names = data['configurations'][0]['results']['best_network']['algorithms'].keys()\n",
    "    for k in data_source_names:\n",
    "        if re.match(r'^[Q]?MC_from_data$', k):\n",
    "            data_source = k\n",
    "            break\n",
    "            \n",
    "    sampling_method = re.search(r'(^[Q]?MC)_from_data$', data_source).group(1)\n",
    "    names = {\n",
    "        \"mean_error_relative\" : \"relative error for mean\",\n",
    "        \"var_error_relative\" : \"relative error for variance\",\n",
    "        \"wasserstein_error_cut\" : \"Wasserstein\",\n",
    "        \"mean_bilevel_error\": \"absolute error bilevel mean\",\n",
    "        \"var_bilevel_error\" :\"absolute error bilevel variance\",\n",
    "        \"prediction_l1_relative\": 'relative prediction error ($L^1$)',\n",
    "        \"prediction_l2_relative\" : 'relative prediction_error ($L^2$)'\n",
    "    }\n",
    "    \n",
    "    competitor_keys = {\n",
    "        \"mean_error_relative\" : \"results.best_network.base_sampling_error.mean_error_relative\",\n",
    "        \"var_error_relative\" : \"results.best_network.base_sampling_error.mean_error_relative\",\n",
    "        \"wasserstein_error_cut\" : \"results.best_network.base_sampling_error.wasserstein_error_cut\",\n",
    "        \"mean_bilevel_error\": \"results.best_network.base_sampling_error.mean_error\",\n",
    "        \"var_bilevel_error\" :\"results.best_network.base_sampling_error.var_error\",\n",
    "        \"prediction_l1_relative\": 'results.best_network.algorithms.{data_source}.lsq.ordinary.prediction_l1_relative'.format(data_source=data_source),\n",
    "        \"prediction_l2_relative\" :  'results.best_network.algorithms.{data_source}.lsq.ordinary.prediction_l2_relative'.format(data_source=data_source),\n",
    "    }\n",
    "    \n",
    "    competitor_names = {\n",
    "        \"mean_error_relative\" : sampling_method,\n",
    "        \"var_error_relative\" : sampling_method,\n",
    "        \"wasserstein_error_cut\" : sampling_method,\n",
    "        \"mean_bilevel_error\": sampling_method,\n",
    "        \"var_bilevel_error\" : sampling_method,\n",
    "        \"prediction_l1_relative\": 'LSQ (with {})'.format(sampling_method),\n",
    "        \"prediction_l2_relative\" : 'LSQ (with {})'.format(sampling_method),\n",
    "    }\n",
    "    \n",
    "    errors = {\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    errors_var = {}\n",
    "    errors_min = {}\n",
    "    \n",
    "    errors_max = {}\n",
    "    \n",
    "    errors_retraining = {}\n",
    "    errors_retraining_var = {}\n",
    "    errors_min = {}\n",
    "    \n",
    "    errors_max = {}\n",
    "    competitor = {}\n",
    "    for k in names.keys():\n",
    "        errors[k] = np.zeros(len(train_sizes))\n",
    "        errors_var[k]  = np.zeros(len(train_sizes))\n",
    "        errors_max[k]  = np.zeros(len(train_sizes))\n",
    "        errors_min[k]  = np.zeros(len(train_sizes))\n",
    "        errors_retraining[k]  = np.zeros(len(train_sizes))\n",
    "        errors_retraining_var[k]  = np.zeros(len(train_sizes))\n",
    "        competitor[k]  = np.zeros(len(train_sizes))\n",
    "        \n",
    "    \n",
    "    for error in errors.keys():\n",
    "        tactics=['ordinary', 'add', 'remove', 'replace']\n",
    "        for t, tactic in enumerate(tactics):\n",
    "            for (n, train_size) in enumerate(train_sizes):\n",
    "                errors_local = []\n",
    "                for configuration in data['configurations']:\n",
    "                    ts = int(configuration['settings']['train_size'])\n",
    "                    if ts == train_size:\n",
    "                        errors_local.append(configuration['results']['best_network']['algorithms'][data_source]['ml'][tactic][error])\n",
    "                        competitor[error][n] = get_dict_path(configuration, competitor_keys[error])\n",
    "                        \n",
    "                \n",
    "                            \n",
    "                errors[error][n] = np.mean(errors_local)\n",
    "                errors_var[error][n] = np.var(errors_local)\n",
    "                errors_min[error][n] = np.amin(errors_local)\n",
    "                errors_max[error][n] = np.amax(errors_local)\n",
    "                \n",
    "                \n",
    "                \n",
    "                errors_local = []\n",
    "                for configuration in data['configurations']:\n",
    "                    ts = int(configuration['settings']['train_size'])\n",
    "                    if ts == train_size:\n",
    "                        retrainings = configuration['results']['retrainings'].keys()\n",
    "                        for retraining in retrainings:\n",
    "                            errors_local.append(configuration['results']['retrainings'][retraining]['algorithms'][data_source]['ml'][tactic][error])\n",
    "                errors_retraining[error][n] = np.mean(errors_local)\n",
    "                errors_retraining_var[error][n] = np.var(errors_local)\n",
    "                \n",
    "                \n",
    "                \n",
    "            plt.figure(0)\n",
    "            \n",
    "            \n",
    "            p = plt.errorbar(train_sizes, errors[error], yerr=np.sqrt(errors_var[error]), label=tactic,\n",
    "                            solid_capstyle='projecting', capsize=5)\n",
    "            plt.figure(t+1)\n",
    "            plt.errorbar(train_sizes, errors[error], yerr=np.sqrt(errors_var[error]),\n",
    "                            solid_capstyle='projecting', capsize=5, label='Machine learning')\n",
    "            \n",
    "            \n",
    "            plt.figure(len(tactics)+1)\n",
    "            p = plt.errorbar(train_sizes, errors_retraining[error], yerr=np.sqrt(errors_retraining_var[error]), label=tactic,\n",
    "                            solid_capstyle='projecting', capsize=5)\n",
    "            \n",
    "            plt.figure(len(tactics)+1+t+1)\n",
    "            plt.errorbar(train_sizes, errors_retraining[error], yerr=np.sqrt(errors_retraining_var[error]),\n",
    "                            solid_capstyle='projecting', capsize=5, label='Machine learning')\n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.figure(2*(len(tactics)+1))\n",
    "            p = plt.errorbar(train_sizes, errors[error], yerr=np.sqrt(errors_var[error]), \\\n",
    "                             label='Selected retraining ({})'.format(tactic), ls='--',\n",
    "                            solid_capstyle='projecting', capsize=5)\n",
    "            \n",
    "            p = plt.errorbar(train_sizes, errors_retraining[error], \n",
    "                             yerr=np.sqrt(errors_retraining_var[error]), \n",
    "                             label='Average of retraining ({})'.format(tactic),\n",
    "                            solid_capstyle='projecting', capsize=10)\n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.figure(2*(len(tactics)+1)+t+1)\n",
    "            p = plt.errorbar(train_sizes, errors[error], yerr=np.sqrt(errors_var[error]), \\\n",
    "                             label='Selected retraining', ls='--',\n",
    "                            solid_capstyle='projecting', capsize=5)\n",
    "            \n",
    "            p = plt.errorbar(train_sizes, errors_retraining[error], \n",
    "                             yerr=np.sqrt(errors_retraining_var[error]), \n",
    "                             label='Average of retraining', \n",
    "                            solid_capstyle='projecting', capsize=10)\n",
    "\n",
    "            \n",
    "            #plt.loglog(train_sizes, errors_min[error], '.--', label='{} minimum'.format(tactic), color=p[0].get_color())\n",
    "            #plt.loglog(train_sizes, errors_max[error], '--', label='{} maximum'.format(tactic), color=p[0].get_color())\n",
    "        plt.figure(0)\n",
    "        \n",
    "        plt.gca().set_xscale(\"log\", nonposx='clip', basex=2)\n",
    "        plt.gca().set_yscale(\"log\", nonposy='clip', basey=2)\n",
    "        plt.title('Average {}\\nConfigurations: {}\\nfor {}'.format(names[error], title, functional))\n",
    "        plt.xlabel(\"Training size\")\n",
    "        plt.ylabel(names[error])\n",
    "        plt.grid(True)\n",
    "        #plt.ylim([max(min(errors[error]-np.sqrt(errors_var[error])),0), max(errors[error]+np.sqrt(errors_var[error]))])\n",
    "        plot_info.savePlot('combined_{functional}_{error}_{title}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                      error=error, title=title))\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.loglog(train_sizes, competitor[error], '--o', label=competitor_names[error], basex=2, basey=2)\n",
    "        plot_info.legendLeft()\n",
    "        plot_info.savePlot('combined_with_compare_{functional}_{error}_{title}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                      error=error, title=title))\n",
    "        \n",
    "        \n",
    "        plt.figure(len(tactics)+1)\n",
    "        \n",
    "        plt.gca().set_xscale(\"log\", nonposx='clip', basex=2)\n",
    "        plt.gca().set_yscale(\"log\", nonposy='clip', basey=2)\n",
    "        plt.title('Average (with retraining variance) {}\\nConfigurations: {}\\nfor {}'.format(names[error], title, functional))\n",
    "        plt.xlabel(\"Training size\")\n",
    "        plt.ylabel(names[error])\n",
    "        plt.grid(True)\n",
    "        #plt.ylim([max(min(errors[error]-np.sqrt(errors_var[error])),0), max(errors[error]+np.sqrt(errors_var[error]))])\n",
    "        plot_info.savePlot('combined_retraining_{functional}_{error}_{title}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                      error=error, title=title))\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.loglog(train_sizes, competitor[error], '--o', label=competitor_names[error], basex=2, basey=2)\n",
    "        plot_info.legendLeft()\n",
    "        plot_info.savePlot('combined_retraining_with_compare_{functional}_{error}_{title}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                      error=error, title=title))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.figure(2*(len(tactics)+1))\n",
    "        \n",
    "        plt.gca().set_xscale(\"log\", nonposx='clip', basex=2)\n",
    "        plt.gca().set_yscale(\"log\", nonposy='clip', basey=2)\n",
    "        plt.title('Average (with retraining variance) {}\\nConfigurations: {}\\nfor {}'.format(names[error], title, functional))\n",
    "        plt.xlabel(\"Training size\")\n",
    "        plt.ylabel(names[error])\n",
    "        plt.grid(True)\n",
    "        #plt.ylim([max(min(errors[error]-np.sqrt(errors_var[error])),0), max(errors[error]+np.sqrt(errors_var[error]))])\n",
    "        plot_info.savePlot('combined_retraining_best_{functional}_{error}_{title}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                      error=error, title=title))\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.loglog(train_sizes, competitor[error], '--o', label=competitor_names[error], basex=2, basey=2)\n",
    "        plot_info.legendLeft()\n",
    "        plot_info.savePlot('combined_retraining_best_with_compare_{functional}_{error}_{title}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                      error=error, title=title))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for t, tactic in enumerate(tactics):\n",
    "            plt.figure(t+1)\n",
    "            plot_info.legendLeft()\n",
    "            plt.gca().set_xscale(\"log\", nonposx='clip', basex=2)\n",
    "            plt.gca().set_yscale(\"log\", nonposy='clip', basey=2)\n",
    "            plt.title('Average {}\\nConfigurations: {}\\n for {}\\n(Using \"{tactic}\" to deal with training samples)'.format(names[error], title, functional,\n",
    "                                                                                                          tactic=tactic))\n",
    "            plt.xlabel(\"Training size\")\n",
    "            plt.ylabel(names[error])\n",
    "            plt.grid(True)\n",
    "            #plt.ylim([max(min(errors[error]-np.sqrt(errors_var[error])),0), max(errors[error]+np.sqrt(errors_var[error]))])\n",
    "            plot_info.savePlot('combined_{functional}_{error}_{title}_{tactic}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                              error=error, title=title,\n",
    "                                                                                                                   tactic=tactic))\n",
    "            \n",
    "            plt.loglog(train_sizes, competitor[error], '--o', label=competitor_names[error], basex=2, basey=2)\n",
    "            plot_info.legendLeft()\n",
    "            plot_info.savePlot('combined_with_compare_{functional}_{error}_{title}_{tactic}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                              error=error, title=title,\n",
    "                                                                                                                   tactic=tactic))\n",
    "            plt.close(t+1)\n",
    "            \n",
    "            \n",
    "            plt.figure(len(tactics)+1+t+1)\n",
    "            plot_info.legendLeft()\n",
    "            plt.gca().set_xscale(\"log\", nonposx='clip', basex=2)\n",
    "            plt.gca().set_yscale(\"log\", nonposy='clip', basey=2)\n",
    "            plt.title('Average (with retraining) {}\\nConfigurations: {}\\n for {}\\n(Using \"{tactic}\" to deal with training samples)'.format(names[error], title, functional,\n",
    "                                                                                                          tactic=tactic))\n",
    "            plt.xlabel(\"Training size\")\n",
    "            plt.ylabel(names[error])\n",
    "            plt.grid(True)\n",
    "            #plt.ylim([max(min(errors[error]-np.sqrt(errors_var[error])),0), max(errors[error]+np.sqrt(errors_var[error]))])\n",
    "            plot_info.savePlot('combined_retraining_{functional}_{error}_{title}_{tactic}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                              error=error, title=title,\n",
    "                                                                                                                   tactic=tactic))\n",
    "            \n",
    "            plt.loglog(train_sizes, competitor[error], '--o', label=competitor_names[error], basex=2, basey=2)\n",
    "            plot_info.legendLeft()\n",
    "            plot_info.savePlot('combined_retraining_with_compare_{functional}_{error}_{title}_{tactic}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                              error=error, title=title,\n",
    "                                                                                                                   tactic=tactic))\n",
    "            \n",
    "            plt.close(len(tactics)+1+t+1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.figure(2*(len(tactics)+1)+t+1)\n",
    "            plot_info.legendLeft()\n",
    "            plt.gca().set_xscale(\"log\", nonposx='clip', basex=2)\n",
    "            plt.gca().set_yscale(\"log\", nonposy='clip', basey=2)\n",
    "            plt.title('Average (with retraining) {}\\nConfigurations: {}\\n for {}\\n(Using \"{tactic}\" to deal with training samples)'.format(names[error], title, functional,\n",
    "                                                                                                          tactic=tactic))\n",
    "            plt.xlabel(\"Training size\")\n",
    "            plot_info.legendLeft()\n",
    "            plt.ylabel(names[error])\n",
    "            plt.grid(True)\n",
    "            #plt.ylim([max(min(errors[error]-np.sqrt(errors_var[error])),0), max(errors[error]+np.sqrt(errors_var[error]))])\n",
    "            plot_info.savePlot('combined_retraining_best_{functional}_{error}_{title}_{tactic}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                              error=error, title=title,\n",
    "                                                                                                                   tactic=tactic))\n",
    "            \n",
    "            plt.loglog(train_sizes, competitor[error], '--o', label=competitor_names[error], basex=2, basey=2)\n",
    "            plot_info.legendLeft()\n",
    "            plot_info.savePlot('combined_retraining_best_with_compare_{functional}_{error}_{title}_{tactic}_convergence_training_size'.format(functional=functional,\n",
    "                                                                                              error=error, title=title,\n",
    "                                                                                                                   tactic=tactic))\n",
    "            \n",
    "            plt.close(2*(len(tactics)+1)+t+1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_configs(data, excludes={}, onlys={}, test_functions = []):\n",
    "    data_copy = {}\n",
    "    \n",
    "    for k in data.keys():\n",
    "        if k != 'configurations':\n",
    "            data_copy[k] = copy.deepcopy(data[k])\n",
    "    data_copy['configurations'] = []\n",
    "    print(len(data['configurations']))\n",
    "    for config in data['configurations']:\n",
    "        keep = True\n",
    "        for exclude_path in excludes.keys():\n",
    "            split = exclude[0].split('.')\n",
    "            value = config\n",
    "            for k in split:\n",
    "                value = value[k]\n",
    "            excluded_values = excludes[exclude_path]\n",
    "            \n",
    "            for excluded_value in excluded_values:\n",
    "                if value == excluded_value:\n",
    "                    keep = False\n",
    "        if not keep:\n",
    "            continue\n",
    "            \n",
    "        for only_path in onlys.keys():\n",
    "            split = only_path[0].split('.')\n",
    "            value = config\n",
    "            for k in split:\n",
    "                value = value[k]\n",
    "            only_values = onlys[only_path]\n",
    "            \n",
    "            equal_to_one = False\n",
    "            for only_value in only_values:\n",
    "                if value == only_value:\n",
    "                    equal_to_one = True\n",
    "            if not equal_to_one:\n",
    "                keep = False\n",
    "        \n",
    "        if not keep:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for test_function in test_functions:\n",
    "            if not test_function(config):\n",
    "                keep = False\n",
    "                \n",
    "        if not keep:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        data_copy['configurations'].append(copy.deepcopy(config))\n",
    "    print(len(data_copy['configurations']))\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def has_regularization(config):\n",
    "    return config['settings']['regularizer'] is not None and config['settings']['regularizer'] != \"None\"\n",
    "\n",
    "def get_regularization(config):\n",
    "    return config['settings']['regularizer']\n",
    "def get_optimizer(config):\n",
    "    return config['settings']['optimizer']\n",
    "\n",
    "def get_loss(config):\n",
    "    return config['settings']['loss']\n",
    "\n",
    "def only_adam_and_no_regularization_for_mse(config):\n",
    "    return get_optimizer(config) == 'Adam' and (get_loss(config) == 'mean_absolute_error' or not has_regularization(config))\n",
    "\n",
    "def only_adam_and_no_regularization_for_mse_and_reg_for_l1(config):\n",
    "    if get_optimizer(config) != 'Adam':\n",
    "        return False\n",
    "    if get_loss(config) == 'mean_absolute_error':\n",
    "        return has_regularization(config)\n",
    "    else:\n",
    "        return not has_regularization(config)\n",
    "    \n",
    "def best_configuration_1(config):\n",
    "    \"\"\"Adam, mean_absolute_error, ray_prediction, l2 reg\"\"\"\n",
    "    if get_optimizer(config) != 'Adam':\n",
    "        return False\n",
    "    \n",
    "    if get_loss(config) != 'mean_absolute_error':\n",
    "        return False\n",
    "    \n",
    "    if get_selection(config) != 'ray_prediction':\n",
    "        return False\n",
    "    \n",
    "    if not has_regularization(config):\n",
    "        return False\n",
    "    \n",
    "    return get_regularization(config)['l2'] > 0 and get_regularization(config)['l1'] == 0\n",
    "\n",
    "def best_configuration_2(config):\n",
    "    \"\"\"Adam, mean_squared_error, train, No reg\"\"\"\n",
    "    if get_optimizer(config) != 'Adam':\n",
    "        return False\n",
    "    \n",
    "    if get_loss(config) != 'mean_squared_error':\n",
    "        return False\n",
    "    \n",
    "    if get_selection(config) != 'train':\n",
    "        return False\n",
    "    \n",
    "    return not has_regularization(config)\n",
    "\n",
    "\n",
    "def best_configuration_3(config):\n",
    "    \"\"\"Adam, mean_absolute_error, wasserstein_train, l2 reg\"\"\"\n",
    "    if get_optimizer(config) != 'Adam':\n",
    "        return False\n",
    "    \n",
    "    if get_loss(config) != 'mean_absolute_error':\n",
    "        return False\n",
    "    \n",
    "    if get_selection(config) != 'wasserstein_train':\n",
    "        return False\n",
    "    \n",
    "    if not has_regularization(config):\n",
    "        return False\n",
    "    \n",
    "    return get_regularization(config)['l2'] > 0 and get_regularization(config)['l1'] == 0\n",
    "\n",
    "\n",
    "def best_configuration_4(config):\n",
    "    \"\"\"Adam, mean_absolute_error, ray_prediction, l1 reg\"\"\"\n",
    "    if get_optimizer(config) != 'Adam':\n",
    "        return False\n",
    "    \n",
    "    if get_loss(config) != 'mean_absolute_error':\n",
    "        return False\n",
    "    \n",
    "    if get_selection(config) != 'ray_prediction':\n",
    "        return False\n",
    "    \n",
    "    if not has_regularization(config):\n",
    "        return False\n",
    "    \n",
    "    return get_regularization(config)['l1'] > 0 and get_regularization(config)['l2'] == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\n",
    "    'All configurations' : lambda x: True,\n",
    "    'Only Adam with ($L^2$ and no regularization) or ($L^1$)' : only_adam_and_no_regularization_for_mse,\n",
    "    'Only Adam with ($L^2$ and no regularization) or ($L^1$ with regularization)' : only_adam_and_no_regularization_for_mse_and_reg_for_l1,\n",
    "}\n",
    "\n",
    "for f in [best_configuration_1, best_configuration_2, best_configuration_3, best_configuration_4]:\n",
    "    filters[f.__doc__] = f\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Drag</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>All configurations</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "1015\n",
      "[64, 128, 256, 32]\n"
     ]
    }
   ],
   "source": [
    "for functional in functionals:\n",
    "    display(HTML(\"<h1>{}</h1>\".format(functional)))\n",
    "    for filtername in filters:\n",
    "        display(HTML(\"<h2>{}</h2>\".format(filtername)))\n",
    "        plot_as_training_size(functional, \\\n",
    "                              filter_configs(data[functional], test_functions=[filters[filtername]]), \\\n",
    "                              filtername)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
